{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Random Forest (Floresta Aleatória)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando a base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edu = pd.read_csv('xAPI-Edu-Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender NationalITy PlaceofBirth     StageID GradeID SectionID Topic  \\\n",
       "0      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "1      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "2      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "3      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "4      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "\n",
       "  Semester Relation  raisedhands  VisITedResources  AnnouncementsView  \\\n",
       "0        F   Father           15                16                  2   \n",
       "1        F   Father           20                20                  3   \n",
       "2        F   Father           10                 7                  0   \n",
       "3        F   Father           30                25                  5   \n",
       "4        F   Father           40                50                 12   \n",
       "\n",
       "   Discussion ParentAnsweringSurvey ParentschoolSatisfaction  \\\n",
       "0          20                   Yes                     Good   \n",
       "1          25                   Yes                     Good   \n",
       "2          30                    No                      Bad   \n",
       "3          35                    No                      Bad   \n",
       "4          50                    No                      Bad   \n",
       "\n",
       "  StudentAbsenceDays Class  \n",
       "0            Under-7     M  \n",
       "1            Under-7     M  \n",
       "2            Above-7     L  \n",
       "3            Above-7     L  \n",
       "4            Above-7     M  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando as distribuições de classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    211\n",
       "H    142\n",
       "L    127\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando os registros nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                      0\n",
       "NationalITy                 0\n",
       "PlaceofBirth                0\n",
       "StageID                     0\n",
       "GradeID                     0\n",
       "SectionID                   0\n",
       "Topic                       0\n",
       "Semester                    0\n",
       "Relation                    0\n",
       "raisedhands                 0\n",
       "VisITedResources            0\n",
       "AnnouncementsView           0\n",
       "Discussion                  0\n",
       "ParentAnsweringSurvey       0\n",
       "ParentschoolSatisfaction    0\n",
       "StudentAbsenceDays          0\n",
       "Class                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codificando os atributos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = df_edu\n",
    "Cat_Colums = Features.dtypes.pipe(lambda Features: Features[Features=='object']).index\n",
    "for col in Cat_Colums:\n",
    "    label = LabelEncoder()\n",
    "    Features[col] = label.fit_transform(Features[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  NationalITy  PlaceofBirth  StageID  GradeID  SectionID  Topic  \\\n",
       "0       1            4             4        2        1          0      7   \n",
       "1       1            4             4        2        1          0      7   \n",
       "2       1            4             4        2        1          0      7   \n",
       "3       1            4             4        2        1          0      7   \n",
       "4       1            4             4        2        1          0      7   \n",
       "\n",
       "   Semester  Relation  raisedhands  VisITedResources  AnnouncementsView  \\\n",
       "0         0         0           15                16                  2   \n",
       "1         0         0           20                20                  3   \n",
       "2         0         0           10                 7                  0   \n",
       "3         0         0           30                25                  5   \n",
       "4         0         0           40                50                 12   \n",
       "\n",
       "   Discussion  ParentAnsweringSurvey  ParentschoolSatisfaction  \\\n",
       "0          20                      1                         1   \n",
       "1          25                      1                         1   \n",
       "2          30                      0                         0   \n",
       "3          35                      0                         0   \n",
       "4          50                      0                         0   \n",
       "\n",
       "   StudentAbsenceDays  Class  \n",
       "0                   1      2  \n",
       "1                   1      2  \n",
       "2                   0      1  \n",
       "3                   0      1  \n",
       "4                   0      2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando os dados e classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_edu.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df_edu['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest vs Árvore de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf = RandomForestClassifier(random_state=1,n_estimators=100)#n_estimator:número de arvores na floresta aleatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_random = cross_val_predict(random_clf, dataset, classes, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65       142\n",
      "           1       0.77      0.78      0.77       127\n",
      "           2       0.63      0.63      0.63       211\n",
      "\n",
      "    accuracy                           0.67       480\n",
      "   macro avg       0.68      0.68      0.68       480\n",
      "weighted avg       0.67      0.67      0.67       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes,resultados_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_tree = cross_val_predict(tree_clf,dataset,classes,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.61      0.55       142\n",
      "           1       0.74      0.68      0.70       127\n",
      "           2       0.54      0.49      0.52       211\n",
      "\n",
      "    accuracy                           0.57       480\n",
      "   macro avg       0.59      0.59      0.59       480\n",
      "weighted avg       0.58      0.57      0.58       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes,resultados_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_edu.drop('Class',axis=1),df_edu['Class'],test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos_random_forest(maxdepth):\n",
    "    if maxdepth == 0:\n",
    "        rf = RandomForestClassifier(n_estimators=100,random_state=1)\n",
    "    else: \n",
    "        rf = RandomForestClassifier(n_estimators=100,random_state=1, max_depth=maxdepth)\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_score = rf.score(X_train, y_train)\n",
    "    test_score = rf.score(X_test, y_test)\n",
    "    return train_score,test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth      Training score       Testing score       \n",
      "-----      --------------       -------------       \n",
      "2         (0.75, 0.6180555555555556) \n",
      "3         (0.8244047619047619, 0.6805555555555556) \n",
      "4         (0.8720238095238095, 0.7152777777777778) \n",
      "10         (1.0, 0.7569444444444444) \n",
      "15         (1.0, 0.7986111111111112) \n",
      "Full         (1.0, 0.7986111111111112) \n"
     ]
    }
   ],
   "source": [
    "print('{:10} {:20} {:20}'.format('depth', 'Training score','Testing score'))\n",
    "print('{:10} {:20} {:20}'.format('-----', '--------------','-------------'))\n",
    "print('{:1}         {} '.format(2,str(compara_modelos_random_forest(2))))\n",
    "print('{:1}         {} '.format(3,str(compara_modelos_random_forest(3))))\n",
    "print('{:1}         {} '.format(4,str(compara_modelos_random_forest(4))))\n",
    "print('{:1}         {} '.format(10,str(compara_modelos_random_forest(10))))\n",
    "print('{:1}         {} '.format(15,str(compara_modelos_random_forest(15))))\n",
    "print('{:1}         {} '.format('Full',str(compara_modelos_random_forest(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos_decision_tree(maxdepth):\n",
    "    if maxdepth == 0:\n",
    "        df = DecisionTreeClassifier(random_state=1)\n",
    "    else: \n",
    "        df = DecisionTreeClassifier(random_state=1, max_depth=maxdepth)\n",
    "    df.fit(X_train, y_train)\n",
    "    train_score = df.score(X_train, y_train)\n",
    "    test_score = df.score(X_test, y_test)\n",
    "    return train_score,test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth      Training score       Testing score       \n",
      "-----      --------------       -------------       \n",
      "2         (0.6398809523809523, 0.6805555555555556) \n",
      "3         (0.7321428571428571, 0.7013888888888888) \n",
      "4         (0.7916666666666666, 0.7430555555555556) \n",
      "10         (0.9910714285714286, 0.6875) \n",
      "15         (1.0, 0.6944444444444444) \n",
      "Full         (1.0, 0.6944444444444444) \n"
     ]
    }
   ],
   "source": [
    "print('{:10} {:20} {:20}'.format('depth', 'Training score','Testing score'))\n",
    "print('{:10} {:20} {:20}'.format('-----', '--------------','-------------'))\n",
    "print('{:1}         {} '.format(2,str(compara_modelos_decision_tree(2))))\n",
    "print('{:1}         {} '.format(3,str(compara_modelos_decision_tree(3))))\n",
    "print('{:1}         {} '.format(4,str(compara_modelos_decision_tree(4))))\n",
    "print('{:1}         {} '.format(10,str(compara_modelos_decision_tree(10))))\n",
    "print('{:1}         {} '.format(15,str(compara_modelos_decision_tree(15))))\n",
    "print('{:1}         {} '.format('Full',str(compara_modelos_decision_tree(0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning do Modelo para Garantir o Melhor Desempenho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como encontrar os melhores valores para os parametros do modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier(\n",
    "n_estimators=?,\n",
    "criterion='gini' ou 'entropy',\n",
    "max_depth=?,\n",
    "min_samples_split=?,\n",
    "min_samples_leaf=?\n",
    ") ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV para testes de Hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de possíveis valores de estimators ou quantidade de árvores da floresta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_estimators = [10, 20, 50, 100, 150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de possíveis valores para o critério de divisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_criterion = ['gini','entropy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de possíveis valores para a profundidade máxima de cada árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_max_depth = [10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de possíveis valores para os parametros min_samples_split e min_samples_leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_min_samples_split = [2, 5, 10,15]\n",
    "valores_min_samples_leaf = [1, 5, 10,15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define um dicionário que recebe as listas de parâmetros e valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_grid = dict(n_estimators=valores_estimators,\n",
    "                       criterion=valores_criterion,\n",
    "                       max_depth=valores_max_depth,\n",
    "                       min_samples_split=valores_min_samples_split,\n",
    "                       min_samples_leaf=valores_min_samples_leaf \n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dicionário com os parametros que serão utilizados no grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 20, 50, 100, 150],\n",
       " 'criterion': ['gini', 'entropy'],\n",
       " 'max_depth': [10, 20, 50, 100],\n",
       " 'min_samples_split': [2, 5, 10, 15],\n",
       " 'min_samples_leaf': [1, 5, 10, 15]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametros_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instancia o GridSearch com o modelo a ser utilizado, parametros, número de folds e scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(rf, parametros_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplica o GridSearch passando as features e classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 20, 50, 100],\n",
       "                         'min_samples_leaf': [1, 5, 10, 15],\n",
       "                         'min_samples_split': [2, 5, 10, 15],\n",
       "                         'n_estimators': [10, 20, 50, 100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(df_edu.drop('Class',axis=1),df_edu['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imprime os scores por combinações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03081055, 0.04817934, 0.11605587, 0.24731998, 0.33526058,\n",
       "        0.02440133, 0.04496684, 0.11102719, 0.22304645, 0.3421803 ,\n",
       "        0.02699885, 0.05681882, 0.11555057, 0.21620426, 0.37485228,\n",
       "        0.03378143, 0.05844297, 0.1398211 , 0.23151264, 0.31903677,\n",
       "        0.02379088, 0.0454092 , 0.10860653, 0.21161399, 0.34412022,\n",
       "        0.02499018, 0.0460258 , 0.11194086, 0.21722608, 0.3187973 ,\n",
       "        0.02622232, 0.04766197, 0.1163703 , 0.22876134, 0.32093883,\n",
       "        0.02440109, 0.04617567, 0.10841804, 0.21478133, 0.33264995,\n",
       "        0.02419229, 0.04393344, 0.10633588, 0.20697393, 0.31633329,\n",
       "        0.02140741, 0.04577384, 0.10621305, 0.21283894, 0.3294806 ,\n",
       "        0.02408609, 0.04397068, 0.10214338, 0.28807988, 0.41892323,\n",
       "        0.02938318, 0.05168538, 0.12896266, 0.22235084, 0.32887716,\n",
       "        0.02278762, 0.05559611, 0.12822738, 0.24736819, 0.31161013,\n",
       "        0.02439127, 0.04417415, 0.10514064, 0.20375419, 0.39853144,\n",
       "        0.02203979, 0.03497629, 0.09737787, 0.1718308 , 0.27741098,\n",
       "        0.02038779, 0.03956633, 0.10752988, 0.21071877, 0.284408  ,\n",
       "        0.02288332, 0.04236984, 0.09432797, 0.19861927, 0.313515  ,\n",
       "        0.02298651, 0.04167972, 0.10104666, 0.19749408, 0.31664696,\n",
       "        0.0201138 , 0.04810815, 0.13274479, 0.23931236, 0.29366159,\n",
       "        0.02162161, 0.04026613, 0.09590187, 0.18946714, 0.2829349 ,\n",
       "        0.02342668, 0.04057326, 0.09920182, 0.19639006, 0.28732543,\n",
       "        0.02167768, 0.03853083, 0.10216131, 0.19204612, 0.28653173,\n",
       "        0.02187147, 0.04058008, 0.09558802, 0.18687644, 0.28643622,\n",
       "        0.01916962, 0.04463267, 0.09795165, 0.1830977 , 0.28886895,\n",
       "        0.02118831, 0.04038115, 0.11014934, 0.17416167, 0.27676792,\n",
       "        0.0155715 , 0.04036036, 0.09419246, 0.17471805, 0.28282499,\n",
       "        0.02098846, 0.04078007, 0.09774342, 0.18657985, 0.33524799,\n",
       "        0.02658496, 0.05317054, 0.1095695 , 0.18127251, 0.27319541,\n",
       "        0.0219872 , 0.0508163 , 0.10249715, 0.18825712, 0.2648016 ,\n",
       "        0.02038078, 0.04474096, 0.09669085, 0.17265635, 0.25623102,\n",
       "        0.01874976, 0.03437176, 0.08749366, 0.16561213, 0.25935612,\n",
       "        0.01562424, 0.0374969 , 0.08124342, 0.17186179, 0.27185974,\n",
       "        0.03124771, 0.05624695, 0.12811441, 0.19061174, 0.28748021,\n",
       "        0.01874924, 0.04061818, 0.09061837, 0.18435936, 0.27498207,\n",
       "        0.01874886, 0.04374628, 0.09686751, 0.17186098, 0.27497478,\n",
       "        0.01874819, 0.04062204, 0.09061823, 0.17811131, 0.3093524 ,\n",
       "        0.02812328, 0.04687228, 0.09999146, 0.17186103, 0.26560516,\n",
       "        0.0187542 , 0.034372  , 0.0937428 , 0.17811184, 0.26872959,\n",
       "        0.01874914, 0.04062147, 0.08436842, 0.1781117 , 0.26247969,\n",
       "        0.01874909, 0.03124819, 0.09374294, 0.17811041, 0.2593554 ,\n",
       "        0.02187285, 0.0374979 , 0.08124356, 0.17498598, 0.26248035,\n",
       "        0.01874914, 0.03437228, 0.08436437, 0.17186136, 0.25278773,\n",
       "        0.01562467, 0.03749704, 0.08436804, 0.17185764, 0.25310612,\n",
       "        0.02187328, 0.03749723, 0.09374294, 0.18123674, 0.25936012,\n",
       "        0.02187357, 0.031248  , 0.08124285, 0.17186294, 0.25310559,\n",
       "        0.01874862, 0.03749747, 0.09061837, 0.1999867 , 0.29060335,\n",
       "        0.01874881, 0.03437219, 0.08436832, 0.17186155, 0.25310559,\n",
       "        0.01874962, 0.03749681, 0.08124442, 0.16873746, 0.25622969,\n",
       "        0.02499804, 0.04062171, 0.0937429 , 0.19061007, 0.28122787,\n",
       "        0.01562405, 0.04062209, 0.09374123, 0.1906106 , 0.27810254,\n",
       "        0.02499866, 0.03437195, 0.08749709, 0.18748136, 0.32497821,\n",
       "        0.01874828, 0.0406219 , 0.08749313, 0.17811193, 0.27185435,\n",
       "        0.01874957, 0.04062161, 0.09061861, 0.17811103, 0.2687295 ,\n",
       "        0.01874766, 0.04062252, 0.0874938 , 0.18302779, 0.26873007,\n",
       "        0.01874962, 0.04374604, 0.11172566, 0.23435726, 0.38273311,\n",
       "        0.03124857, 0.05936885, 0.12499046, 0.24998612, 0.28198476,\n",
       "        0.01562386, 0.04999604, 0.07811823, 0.16873651, 0.26560531,\n",
       "        0.01874924, 0.03749661, 0.08620687, 0.17445016, 0.27121377,\n",
       "        0.01578283, 0.03754573, 0.09199023, 0.16911459, 0.27185478,\n",
       "        0.02187304, 0.04090309, 0.11611943, 0.18113861, 0.26248002,\n",
       "        0.01874523, 0.03749704, 0.0874927 , 0.1812367 , 0.25623145,\n",
       "        0.01562476, 0.03437204, 0.08124433, 0.16666651, 0.25444369,\n",
       "        0.021874  , 0.04062133, 0.08124795, 0.16248722, 0.25310512,\n",
       "        0.01874852, 0.04062247, 0.0781189 , 0.17498693, 0.31247935,\n",
       "        0.02499843, 0.03749723, 0.0999958 , 0.19685497, 0.28747854,\n",
       "        0.02187366, 0.04062104, 0.10311794, 0.19373436, 0.29372702,\n",
       "        0.018749  , 0.04062085, 0.09374256, 0.19686055, 0.28122878,\n",
       "        0.02187357, 0.03749676, 0.09061861, 0.19373603, 0.27810369,\n",
       "        0.01874886, 0.03749681, 0.09061804, 0.17811136, 0.28122911,\n",
       "        0.01562443, 0.04374619, 0.09061761, 0.19061074, 0.27810431,\n",
       "        0.01874876, 0.03437204, 0.08436747, 0.17811117, 0.27185426,\n",
       "        0.01874881, 0.03749681, 0.08749261, 0.18436131, 0.27810516,\n",
       "        0.02187409, 0.04062104, 0.09374266, 0.21873517, 0.30935416,\n",
       "        0.01874886, 0.03124709, 0.08436828, 0.17811165, 0.26560531,\n",
       "        0.0187489 , 0.03749666, 0.08124318, 0.1781117 , 0.26247978,\n",
       "        0.01874924, 0.03749714, 0.09061832, 0.17811198, 0.25935578,\n",
       "        0.01874881, 0.03124738, 0.09061871, 0.1687376 , 0.25935364,\n",
       "        0.01874866, 0.03124747, 0.09061885, 0.16873727, 0.25622964,\n",
       "        0.01874914, 0.03437247, 0.08124299, 0.17499051, 0.26560102,\n",
       "        0.0187489 , 0.03749619, 0.09061823, 0.17498641, 0.25310655,\n",
       "        0.02187366, 0.04062147, 0.10624242, 0.20311027, 0.29685097,\n",
       "        0.01874919, 0.04062171, 0.09686589, 0.19685974, 0.34372678,\n",
       "        0.02812314, 0.05312109, 0.0999927 , 0.18748407, 0.31872678,\n",
       "        0.02187381, 0.04062166, 0.08749185, 0.19373584, 0.28435507,\n",
       "        0.02499785, 0.03749681, 0.09374299, 0.18436108, 0.27497921,\n",
       "        0.02187414, 0.04374671, 0.09061751, 0.19061193, 0.28435283,\n",
       "        0.01562414, 0.03437214, 0.0999928 , 0.18748646, 0.28122745,\n",
       "        0.0187489 , 0.04374604, 0.09686828, 0.18748641, 0.28747835,\n",
       "        0.01874814, 0.03437223, 0.09374309, 0.18123651, 0.25623107,\n",
       "        0.02187343, 0.03125176, 0.09373932, 0.17186093, 0.26560454,\n",
       "        0.01874838, 0.04062214, 0.07811894, 0.18123608, 0.31247735,\n",
       "        0.02187343, 0.04374671, 0.09686675, 0.17811069, 0.26247578,\n",
       "        0.02187386, 0.03437185, 0.0906188 , 0.16873713, 0.2744226 ,\n",
       "        0.02258668, 0.04018497, 0.16257033, 0.19569788, 0.39655695,\n",
       "        0.01874881, 0.04061766, 0.09579611, 0.26440334, 0.28202133,\n",
       "        0.02233052, 0.03978634, 0.09925737, 0.17239046, 0.44197226,\n",
       "        0.03877754, 0.08255248, 0.1178545 , 0.20913138, 0.33542981,\n",
       "        0.03946452, 0.07735853, 0.15131235, 0.23825045, 0.33921838,\n",
       "        0.02222953, 0.04834156, 0.1171967 , 0.25074754, 0.38729639,\n",
       "        0.01606121, 0.04709616, 0.10387888, 0.21398735, 0.37118864,\n",
       "        0.0312479 , 0.04813218, 0.08933859, 0.19005275, 0.29019094,\n",
       "        0.03857565, 0.08970108, 0.16990323, 0.24854689, 0.30143266,\n",
       "        0.02686448, 0.04518185, 0.10228477, 0.21954074, 0.2983201 ,\n",
       "        0.02279043, 0.04341111, 0.13328247, 0.25955496, 0.59583349,\n",
       "        0.02479444, 0.04128828, 0.12310424, 0.28165455, 0.36277065,\n",
       "        0.02618532, 0.05695548, 0.12912703, 0.44165206, 0.44554462,\n",
       "        0.03898125, 0.05990052, 0.12691293, 0.26811185, 0.54751348,\n",
       "        0.03458734, 0.07745929, 0.14656835, 0.35892525, 0.37133331,\n",
       "        0.02339044, 0.04517331, 0.10533962, 0.23236508, 0.34843931,\n",
       "        0.02498674, 0.05916681, 0.18763652, 0.19737244, 0.28446622,\n",
       "        0.01780734, 0.03608627, 0.09774723, 0.21638145, 0.2959826 ,\n",
       "        0.02009559, 0.04489522, 0.11419291, 0.2258132 , 0.30923691,\n",
       "        0.01874919, 0.05783639, 0.13317232, 0.21489482, 0.32865534,\n",
       "        0.03866806, 0.04578266, 0.11138062, 0.27114658, 0.41574011,\n",
       "        0.04070868, 0.0780292 , 0.23602862, 0.35092969, 1.05666327,\n",
       "        0.08263826, 0.10697017, 0.11471014, 0.34312162, 0.46928749,\n",
       "        0.07979846, 0.10100622, 0.26562057, 0.34014931, 0.7356657 ,\n",
       "        0.04461508, 0.06644726, 0.19443669, 0.62052855, 0.48014603,\n",
       "        0.02435079, 0.03441691, 0.09950957, 0.21097999, 0.35751777,\n",
       "        0.02519817, 0.0442626 , 0.1428597 , 0.25315623, 0.51383834,\n",
       "        0.02162995, 0.04065824, 0.10272946, 0.2198709 , 0.33610306,\n",
       "        0.02158761, 0.04147592, 0.12024021, 0.19012036, 0.271106  ,\n",
       "        0.01874895, 0.03437233, 0.090487  , 0.19359918, 0.34257798,\n",
       "        0.02499819, 0.05300064, 0.11290307, 0.18669577, 0.29642944,\n",
       "        0.02421608, 0.04747591, 0.16893983, 0.3755969 , 0.42084022,\n",
       "        0.0318841 , 0.04973054, 0.18474207, 0.29250474, 0.59348936,\n",
       "        0.02299085, 0.05509949, 0.15099416, 0.32668967, 0.5077498 ,\n",
       "        0.0235908 , 0.04210138, 0.09656143, 0.19347935, 0.28451672]),\n",
       " 'std_fit_time': array([6.49978565e-03, 3.53895756e-03, 3.44757551e-03, 8.45779124e-03,\n",
       "        7.14411935e-03, 1.05879043e-03, 2.09205010e-03, 2.37633743e-03,\n",
       "        4.16301635e-03, 1.44440734e-02, 3.72238945e-03, 1.56730072e-03,\n",
       "        9.49993737e-03, 4.54651780e-03, 4.92682786e-02, 6.70090572e-03,\n",
       "        3.53727552e-03, 2.14520895e-02, 1.76913552e-02, 5.84956888e-03,\n",
       "        2.31805975e-03, 1.02505509e-03, 5.72748488e-03, 4.22611506e-03,\n",
       "        3.10239983e-02, 1.41307255e-03, 2.57810930e-03, 5.24564476e-03,\n",
       "        5.17305451e-03, 5.21734465e-03, 1.65300664e-03, 2.73152913e-03,\n",
       "        7.37649081e-03, 1.48578695e-02, 1.00782393e-02, 1.87104264e-03,\n",
       "        2.78489475e-03, 2.44690179e-03, 4.48420591e-03, 2.06999381e-02,\n",
       "        7.39961049e-04, 2.73079180e-03, 4.71818445e-03, 5.14375222e-03,\n",
       "        7.91621355e-03, 3.16846734e-03, 2.48146774e-03, 3.47221259e-03,\n",
       "        2.20721222e-03, 2.70599429e-02, 2.00884510e-03, 3.27977786e-03,\n",
       "        1.47144724e-03, 8.36593758e-02, 7.17982344e-02, 1.01955551e-03,\n",
       "        3.52966361e-03, 1.81992895e-02, 5.49342291e-03, 1.37650495e-02,\n",
       "        7.47770285e-04, 9.37435007e-03, 2.14393161e-02, 6.53977978e-03,\n",
       "        1.47982910e-02, 2.15655784e-03, 1.16610592e-03, 3.75187144e-03,\n",
       "        2.00792230e-03, 9.89110995e-02, 5.15935221e-03, 1.87711076e-04,\n",
       "        4.94500307e-03, 8.81281904e-03, 1.52118432e-02, 4.81197132e-04,\n",
       "        1.20806539e-03, 1.70004075e-02, 6.47723751e-02, 3.16312861e-02,\n",
       "        1.51206167e-03, 1.77521321e-03, 3.47473393e-03, 8.73505990e-03,\n",
       "        7.32354259e-03, 8.94843359e-04, 8.73961650e-04, 1.37898889e-03,\n",
       "        7.36532704e-03, 3.60751381e-02, 3.97468804e-03, 6.67158268e-03,\n",
       "        7.39549451e-03, 3.53260891e-02, 6.50446417e-03, 8.19589084e-04,\n",
       "        7.42971430e-04, 7.25216633e-03, 9.24808133e-03, 1.42783620e-02,\n",
       "        7.22558013e-03, 1.36024292e-03, 3.87494178e-03, 4.07894491e-03,\n",
       "        1.94288279e-02, 5.93854697e-04, 5.76638597e-03, 5.72740292e-03,\n",
       "        2.02929909e-03, 6.52835899e-03, 6.55914258e-03, 7.86123859e-04,\n",
       "        6.84003309e-03, 1.04407674e-02, 5.93889506e-03, 6.09371826e-03,\n",
       "        5.63882052e-03, 2.75763991e-03, 5.91655175e-03, 5.46972104e-03,\n",
       "        3.99565736e-04, 1.49573335e-03, 2.85889971e-02, 1.35093348e-02,\n",
       "        1.06563989e-02, 5.51894346e-03, 3.28027281e-03, 6.17834128e-03,\n",
       "        1.17760310e-02, 8.10616158e-03, 1.09358126e-03, 7.48588901e-04,\n",
       "        4.07642518e-03, 5.84409531e-03, 5.05973973e-02, 1.62366299e-03,\n",
       "        2.31298983e-03, 1.07833308e-02, 5.67066620e-03, 5.01674825e-03,\n",
       "        1.41068117e-03, 1.03551370e-02, 5.10096429e-03, 1.32675002e-02,\n",
       "        1.66920310e-02, 7.98975107e-04, 7.31840874e-03, 8.75602971e-03,\n",
       "        7.98267896e-03, 7.66217549e-03, 6.24940398e-03, 6.24852197e-03,\n",
       "        7.65502534e-03, 7.65504488e-03, 7.65549257e-03, 1.05982355e-06,\n",
       "        7.65222235e-03, 6.24959485e-03, 9.88099395e-03, 2.72426550e-02,\n",
       "        9.87955434e-03, 1.24977589e-02, 2.68810304e-02, 6.25997036e-03,\n",
       "        7.65309818e-03, 6.24825064e-03, 7.65035688e-03, 6.24930873e-03,\n",
       "        6.24910657e-03, 7.65753901e-03, 6.24938017e-03, 6.24969024e-03,\n",
       "        6.25052470e-03, 9.88121302e-03, 7.65810503e-03, 6.24887950e-03,\n",
       "        7.65399360e-03, 6.25007159e-03, 7.65512270e-03, 3.18663751e-02,\n",
       "        6.25021547e-03, 9.88143925e-03, 1.59338097e-02, 9.88339955e-03,\n",
       "        9.88121302e-03, 6.24742978e-03, 6.24840262e-03, 2.42066384e-02,\n",
       "        7.65411050e-03, 6.24996343e-03, 6.24865504e-03, 7.65323448e-03,\n",
       "        7.65545359e-03, 7.65510323e-03, 6.24890330e-03, 6.24783071e-03,\n",
       "        2.25982582e-06, 7.92181383e-07, 7.65605721e-03, 1.24994993e-02,\n",
       "        7.65359778e-03, 7.65335122e-03, 6.24988082e-03, 1.16920295e-02,\n",
       "        6.24947571e-03, 6.24840279e-03, 6.24921325e-03, 7.65808471e-03,\n",
       "        9.88205034e-03, 9.27088173e-03, 1.59295016e-06, 7.65385743e-03,\n",
       "        7.65508379e-03, 7.13728227e-06, 6.24966623e-03, 7.65303988e-03,\n",
       "        7.65302028e-03, 2.03202016e-06, 7.65502546e-03, 7.65837723e-03,\n",
       "        7.65300080e-03, 1.33684595e-06, 6.24904636e-03, 1.18347870e-06,\n",
       "        1.16914304e-02, 6.24783042e-03, 7.65409093e-03, 6.24990469e-03,\n",
       "        1.53080067e-02, 2.72421722e-02, 6.24928479e-03, 6.24830727e-03,\n",
       "        7.65465547e-03, 7.62939453e-07, 1.16925775e-02, 6.24899868e-03,\n",
       "        7.65318896e-03, 6.24909445e-03, 1.16924500e-02, 1.59332390e-02,\n",
       "        7.65296189e-03, 7.65488923e-03, 1.12234137e-06, 1.16932912e-02,\n",
       "        1.53331139e-06, 1.97758115e-06, 7.65617429e-03, 9.88038480e-03,\n",
       "        6.25052481e-03, 1.16924118e-02, 7.65414957e-03, 6.24985699e-03,\n",
       "        7.65792963e-03, 9.88106494e-03, 4.12206702e-02, 6.24799734e-03,\n",
       "        7.65465554e-03, 7.65245603e-03, 7.65442200e-03, 7.65507366e-03,\n",
       "        6.24771154e-03, 7.65237784e-03, 6.24907019e-03, 7.65438307e-03,\n",
       "        6.25000005e-03, 6.24890342e-03, 7.65282565e-03, 7.65348749e-03,\n",
       "        7.85743771e-03, 1.16913797e-02, 6.24864105e-03, 1.16912393e-02,\n",
       "        6.79854839e-03, 5.84568718e-02, 7.05737119e-02, 9.88174084e-03,\n",
       "        1.16927565e-02, 9.88008241e-03, 7.32787494e-02, 2.37608393e-02,\n",
       "        7.89305942e-07, 1.16901688e-02, 1.22129903e-06, 6.24957110e-03,\n",
       "        9.88076069e-03, 6.24918951e-03, 7.65498649e-03, 7.01370490e-03,\n",
       "        9.37624231e-03, 1.25055831e-02, 1.87704220e-03, 5.90670132e-03,\n",
       "        1.02473374e-02, 8.64962804e-03, 1.59403124e-02, 7.65440306e-03,\n",
       "        7.89892936e-03, 7.30202779e-03, 1.18153105e-02, 1.16921823e-02,\n",
       "        6.26037759e-03, 7.65376006e-03, 7.65580407e-03, 7.65333186e-03,\n",
       "        7.65578455e-03, 1.46195504e-06, 6.24873659e-03, 6.24949936e-03,\n",
       "        9.89364352e-03, 1.16403740e-02, 7.65333173e-03, 7.65438317e-03,\n",
       "        6.24828857e-03, 7.65457768e-03, 6.25064396e-03, 6.24942782e-03,\n",
       "        7.65346806e-03, 6.14361702e-07, 1.53080359e-02, 2.42069770e-02,\n",
       "        7.65317598e-03, 7.65350705e-03, 7.65078599e-03, 7.65797702e-03,\n",
       "        7.65387683e-03, 7.65321495e-03, 7.65356540e-03, 7.65512269e-03,\n",
       "        7.65486958e-03, 1.16915706e-02, 6.24907024e-03, 7.65438309e-03,\n",
       "        1.30063836e-06, 7.65502541e-03, 1.68587394e-06, 7.65251415e-03,\n",
       "        7.65292294e-03, 6.25002392e-03, 1.24990584e-02, 6.24876068e-03,\n",
       "        6.24866488e-03, 7.65424676e-03, 6.24961855e-03, 7.65381841e-03,\n",
       "        9.88136392e-03, 1.60007112e-06, 6.24916563e-03, 6.25035769e-03,\n",
       "        6.24985706e-03, 1.16912903e-02, 6.24954706e-03, 6.24909412e-03,\n",
       "        7.65438293e-03, 7.65358488e-03, 7.65455818e-03, 6.24892715e-03,\n",
       "        7.65268936e-03, 7.65465546e-03, 6.24995252e-03, 1.16922843e-02,\n",
       "        7.65335124e-03, 7.66155371e-03, 9.88241931e-03, 2.96454232e-02,\n",
       "        3.74993563e-02, 6.24854572e-03, 1.37706080e-06, 7.65391583e-03,\n",
       "        7.65514222e-03, 9.88158996e-03, 6.24876025e-03, 7.65523990e-03,\n",
       "        6.24983333e-03, 7.65374059e-03, 1.16923098e-02, 6.24918953e-03,\n",
       "        7.65377947e-03, 6.25035772e-03, 7.65486967e-03, 7.65288406e-03,\n",
       "        6.24892715e-03, 1.08735602e-06, 6.24995232e-03, 6.25000003e-03,\n",
       "        7.65346802e-03, 6.24876027e-03, 7.92181383e-07, 6.24883176e-03,\n",
       "        6.24971418e-03, 7.65424669e-03, 6.24864103e-03, 6.24947549e-03,\n",
       "        6.25016690e-03, 6.24759575e-03, 7.03815522e-06, 6.24852182e-03,\n",
       "        7.66312972e-03, 6.25031002e-03, 1.16921696e-02, 6.24992861e-03,\n",
       "        7.65292298e-03, 7.65508373e-03, 6.24966622e-03, 8.71451706e-07,\n",
       "        1.48815980e-06, 6.24897484e-03, 7.65401322e-03, 6.25038153e-03,\n",
       "        7.65494755e-03, 3.82725181e-02, 1.16935205e-02, 7.65346843e-03,\n",
       "        1.25013830e-02, 7.44843452e-07, 3.50768231e-02, 7.65231950e-03,\n",
       "        7.65475304e-03, 7.65432454e-03, 7.65346804e-03, 6.24923715e-03,\n",
       "        7.65426621e-03, 7.65492800e-03, 1.02934995e-06, 6.25054845e-03,\n",
       "        7.65354602e-03, 7.65292313e-03, 6.24918941e-03, 6.25007174e-03,\n",
       "        1.16922207e-02, 6.24892728e-03, 1.13443158e-06, 6.25023852e-03,\n",
       "        7.65362376e-03, 1.26519195e-06, 3.56832255e-07, 6.24852189e-03,\n",
       "        6.24980943e-03, 6.25073931e-03, 2.50963161e-06, 7.65432474e-03,\n",
       "        6.24938030e-03, 6.24899866e-03, 6.21719590e-07, 7.65385743e-03,\n",
       "        7.65434411e-03, 7.65282558e-03, 6.81827117e-06, 9.87684129e-03,\n",
       "        1.07684992e-06, 9.88151455e-03, 6.24818802e-03, 7.65377946e-03,\n",
       "        8.74056949e-07, 7.65360433e-03, 4.07432230e-02, 7.65525898e-03,\n",
       "        6.24930962e-03, 1.16927178e-02, 7.65398448e-03, 6.24778738e-03,\n",
       "        7.65325397e-03, 6.25026236e-03, 6.24916574e-03, 6.25059605e-03,\n",
       "        2.87497323e-02, 4.88795060e-04, 4.69426508e-03, 5.20413862e-02,\n",
       "        3.36637199e-02, 1.39156164e-01, 6.23915780e-03, 7.65090010e-03,\n",
       "        9.88486176e-03, 6.82858694e-02, 1.18028566e-02, 3.06533640e-03,\n",
       "        7.12969182e-03, 8.13183278e-03, 9.94407084e-03, 1.24796911e-01,\n",
       "        6.48928766e-03, 1.90207157e-02, 7.92862818e-03, 1.62918291e-02,\n",
       "        4.20225287e-02, 1.42194782e-02, 1.87794200e-02, 1.93569018e-02,\n",
       "        2.37525282e-02, 5.98421152e-02, 7.39120646e-03, 1.22125138e-02,\n",
       "        1.26071014e-02, 3.39274410e-02, 6.18940808e-02, 5.25714753e-03,\n",
       "        8.59549989e-03, 4.15513741e-03, 1.78676341e-02, 6.14880331e-02,\n",
       "        9.88158998e-03, 1.47834192e-02, 9.53409388e-03, 1.30048846e-02,\n",
       "        2.36044919e-02, 1.98348322e-02, 4.66266876e-02, 4.90793496e-02,\n",
       "        7.18820607e-02, 6.40780257e-03, 5.85730820e-03, 1.71074265e-03,\n",
       "        1.29672548e-02, 4.39094628e-02, 2.57242341e-02, 7.48147548e-04,\n",
       "        6.01034566e-03, 4.92204107e-02, 3.82307085e-02, 1.84832314e-01,\n",
       "        4.73687353e-03, 5.30518252e-03, 2.08230803e-02, 7.76918959e-02,\n",
       "        7.80612620e-02, 8.22681285e-03, 3.22333056e-02, 2.69168293e-02,\n",
       "        4.87462669e-02, 1.12607353e-01, 2.03730122e-02, 7.30707652e-03,\n",
       "        2.97946399e-03, 3.86661413e-02, 1.48176162e-01, 6.55962946e-03,\n",
       "        3.39286632e-02, 2.76317909e-02, 4.46878419e-02, 5.65504751e-02,\n",
       "        1.01760574e-03, 1.72012443e-03, 3.19919429e-03, 2.54703642e-02,\n",
       "        4.48314014e-02, 1.67222992e-03, 1.32503150e-02, 4.44387848e-02,\n",
       "        3.08627560e-02, 2.76096963e-02, 3.82487241e-03, 6.32996224e-03,\n",
       "        7.47594779e-03, 6.62758563e-02, 1.90221303e-02, 5.77466742e-03,\n",
       "        3.78298998e-03, 3.26582568e-02, 4.81018285e-02, 3.54779333e-02,\n",
       "        6.25195513e-03, 5.75909095e-03, 2.14584917e-02, 5.28272875e-03,\n",
       "        3.19730178e-02, 9.19114072e-03, 9.09429541e-03, 2.70450596e-03,\n",
       "        8.97730597e-02, 4.68844834e-02, 3.63269879e-03, 1.58198774e-02,\n",
       "        9.03253955e-02, 1.06811805e-01, 4.95319677e-01, 3.86190509e-02,\n",
       "        5.13731465e-02, 7.54003332e-03, 1.27883159e-01, 1.26172637e-01,\n",
       "        6.18964666e-02, 3.74366624e-02, 1.50006936e-01, 1.42922447e-01,\n",
       "        1.35829271e-01, 2.54506207e-03, 1.65924052e-02, 7.62802126e-02,\n",
       "        1.17002659e-01, 8.50432098e-02, 5.17305970e-03, 2.91550269e-03,\n",
       "        9.68601972e-03, 1.41456371e-02, 9.35476247e-02, 1.61596399e-03,\n",
       "        2.37102012e-03, 6.03978108e-02, 2.99606591e-02, 1.44677455e-01,\n",
       "        1.64699592e-03, 1.80629361e-03, 8.30532287e-03, 1.33354349e-02,\n",
       "        4.54857364e-02, 8.05625615e-04, 9.57613826e-03, 1.86381569e-02,\n",
       "        5.90437359e-03, 6.16461892e-03, 6.24825968e-03, 6.24942789e-03,\n",
       "        6.23522486e-03, 1.39490656e-02, 2.75094115e-02, 7.65230032e-03,\n",
       "        1.09746766e-02, 5.19521803e-03, 9.12486709e-03, 1.78229985e-02,\n",
       "        3.28986806e-03, 1.12549651e-02, 9.24776606e-02, 1.19566155e-01,\n",
       "        4.45777927e-02, 9.47752315e-03, 3.97546578e-03, 2.76086939e-02,\n",
       "        1.39556787e-02, 2.13236001e-01, 6.34678703e-03, 5.16710396e-03,\n",
       "        1.73842843e-02, 2.54983217e-02, 2.24378466e-01, 2.79357568e-03,\n",
       "        1.83297136e-03, 7.37375710e-03, 1.36882213e-02, 2.16015307e-02]),\n",
       " 'mean_score_time': array([0.00399499, 0.00339761, 0.00839024, 0.01799655, 0.02080836,\n",
       "        0.00320292, 0.00560384, 0.00818605, 0.01499133, 0.02099152,\n",
       "        0.00399814, 0.00479689, 0.00902996, 0.01439466, 0.02350311,\n",
       "        0.00419664, 0.00459814, 0.00919461, 0.01519575, 0.01937785,\n",
       "        0.00259843, 0.00359755, 0.00799518, 0.01360703, 0.02099252,\n",
       "        0.00299764, 0.00399737, 0.00924234, 0.01369328, 0.01961851,\n",
       "        0.00259714, 0.00439711, 0.00799708, 0.01638646, 0.02028923,\n",
       "        0.0035984 , 0.00439696, 0.00859504, 0.01374068, 0.02258663,\n",
       "        0.00259132, 0.00459251, 0.00819798, 0.01498423, 0.01798182,\n",
       "        0.00456448, 0.00439711, 0.00865521, 0.01618304, 0.01958761,\n",
       "        0.0026021 , 0.00499873, 0.00719337, 0.02128959, 0.02558146,\n",
       "        0.00319805, 0.00579438, 0.00923352, 0.01318169, 0.02098851,\n",
       "        0.00279918, 0.00539784, 0.01079488, 0.017031  , 0.01959181,\n",
       "        0.00279703, 0.00359764, 0.00779538, 0.01378126, 0.02680397,\n",
       "        0.00298872, 0.00301909, 0.00719891, 0.01144147, 0.01789856,\n",
       "        0.00319834, 0.00380712, 0.00883822, 0.01481752, 0.01826234,\n",
       "        0.0011179 , 0.00322895, 0.00865474, 0.01149011, 0.0200912 ,\n",
       "        0.00240312, 0.00420046, 0.00759349, 0.01445994, 0.01901598,\n",
       "        0.00120001, 0.00479875, 0.01112108, 0.01810532, 0.01932416,\n",
       "        0.00319781, 0.00399294, 0.00912609, 0.01432834, 0.01853724,\n",
       "        0.00159845, 0.00399756, 0.007199  , 0.01320252, 0.01723971,\n",
       "        0.00279822, 0.00259824, 0.0069953 , 0.0127883 , 0.01875525,\n",
       "        0.00179901, 0.00399728, 0.00440149, 0.01311569, 0.01705141,\n",
       "        0.        , 0.00399685, 0.00718861, 0.0123158 , 0.01780143,\n",
       "        0.00279799, 0.00380154, 0.0073226 , 0.01196847, 0.02047238,\n",
       "        0.00412498, 0.00299883, 0.00539289, 0.00625005, 0.0185977 ,\n",
       "        0.00279422, 0.00399413, 0.00759988, 0.01180921, 0.02271371,\n",
       "        0.00359774, 0.00419664, 0.00779552, 0.01220074, 0.01997418,\n",
       "        0.00240245, 0.00672679, 0.00739884, 0.01331477, 0.016887  ,\n",
       "        0.00300217, 0.00379782, 0.00439754, 0.0117744 , 0.01562452,\n",
       "        0.00312405, 0.00312476, 0.00624971, 0.0156251 , 0.01250029,\n",
       "        0.00624971, 0.        , 0.0062501 , 0.01562538, 0.01874456,\n",
       "        0.        , 0.00312467, 0.009375  , 0.01249895, 0.01874933,\n",
       "        0.00625277, 0.00312457, 0.00937505, 0.01250129, 0.01874804,\n",
       "        0.00312448, 0.        , 0.00312543, 0.01562605, 0.01563034,\n",
       "        0.00312471, 0.        , 0.00624995, 0.00625038, 0.01562452,\n",
       "        0.        , 0.00312495, 0.00937505, 0.01250081, 0.01562505,\n",
       "        0.00312018, 0.00624952, 0.01249976, 0.01250024, 0.01562529,\n",
       "        0.        , 0.        , 0.01250014, 0.00625033, 0.01875038,\n",
       "        0.00312467, 0.00937395, 0.0031251 , 0.00937614, 0.01562514,\n",
       "        0.00312481, 0.0031249 , 0.00937495, 0.00937572, 0.01562538,\n",
       "        0.00312438, 0.0031251 , 0.00937896, 0.01250086, 0.01652665,\n",
       "        0.00312438, 0.00624943, 0.00625472, 0.01250076, 0.01562533,\n",
       "        0.        , 0.        , 0.        , 0.00624981, 0.01562133,\n",
       "        0.        , 0.00624924, 0.0125    , 0.00937481, 0.01562576,\n",
       "        0.00312452, 0.        , 0.003125  , 0.01562357, 0.00937357,\n",
       "        0.        , 0.00312467, 0.00937552, 0.00937524, 0.01562524,\n",
       "        0.        , 0.        , 0.00624971, 0.00937543, 0.01562624,\n",
       "        0.        , 0.        , 0.00937538, 0.01250038, 0.01875129,\n",
       "        0.00624976, 0.00312476, 0.009376  , 0.00937562, 0.01562648,\n",
       "        0.        , 0.00624948, 0.01250038, 0.01249952, 0.01874881,\n",
       "        0.00312462, 0.        , 0.00937486, 0.01250005, 0.01874976,\n",
       "        0.        , 0.00312462, 0.00312481, 0.01250105, 0.01562552,\n",
       "        0.00312514, 0.00312467, 0.0062499 , 0.00937529, 0.01562495,\n",
       "        0.00312428, 0.        , 0.00048566, 0.01250057, 0.02469926,\n",
       "        0.        , 0.00625153, 0.01562371, 0.01249995, 0.01562486,\n",
       "        0.00624933, 0.0062499 , 0.01562548, 0.012501  , 0.0125001 ,\n",
       "        0.00312462, 0.00312514, 0.00937457, 0.00792298, 0.01366138,\n",
       "        0.00039978, 0.00472403, 0.00591874, 0.01489863, 0.01562595,\n",
       "        0.00312495, 0.00312476, 0.00937543, 0.01217246, 0.01563044,\n",
       "        0.00312448, 0.        , 0.0062501 , 0.00937543, 0.01562448,\n",
       "        0.00624909, 0.00312467, 0.01249971, 0.01351862, 0.01562562,\n",
       "        0.        , 0.        , 0.01249609, 0.01562514, 0.01562552,\n",
       "        0.        , 0.        , 0.01249986, 0.00937457, 0.01562338,\n",
       "        0.        , 0.00937476, 0.00624614, 0.01563044, 0.01875024,\n",
       "        0.        , 0.00312505, 0.0031249 , 0.01562629, 0.01875124,\n",
       "        0.00312443, 0.00312538, 0.00937524, 0.00937552, 0.01875024,\n",
       "        0.        , 0.00624924, 0.00937452, 0.00937524, 0.01562529,\n",
       "        0.00312481, 0.00312486, 0.01249967, 0.01250038, 0.01562552,\n",
       "        0.00312452, 0.        , 0.00937548, 0.00625048, 0.01562543,\n",
       "        0.00312452, 0.00624986, 0.01250043, 0.01562548, 0.01562605,\n",
       "        0.00312481, 0.        , 0.00937533, 0.01249995, 0.01874909,\n",
       "        0.        , 0.00312567, 0.0031251 , 0.01249847, 0.01874847,\n",
       "        0.00312457, 0.0062499 , 0.00937519, 0.00937524, 0.01874995,\n",
       "        0.00312462, 0.003125  , 0.01250057, 0.00625005, 0.01562543,\n",
       "        0.        , 0.00312514, 0.00624957, 0.00937448, 0.01562576,\n",
       "        0.00312433, 0.00624967, 0.00312495, 0.01562524, 0.01562648,\n",
       "        0.        , 0.00624967, 0.00312457, 0.01250057, 0.01562581,\n",
       "        0.00312524, 0.00312462, 0.00937538, 0.00625029, 0.01562586,\n",
       "        0.00312443, 0.        , 0.00312514, 0.00937572, 0.01562486,\n",
       "        0.00312476, 0.00312519, 0.00312514, 0.00937505, 0.01875167,\n",
       "        0.00312467, 0.00312486, 0.00312514, 0.00937581, 0.01562343,\n",
       "        0.0031249 , 0.00312409, 0.0125001 , 0.0156261 , 0.01874986,\n",
       "        0.        , 0.00624967, 0.01250091, 0.00625005, 0.01562428,\n",
       "        0.        , 0.00312538, 0.00624986, 0.00937505, 0.02187471,\n",
       "        0.        , 0.        , 0.00937552, 0.00624976, 0.0156261 ,\n",
       "        0.00312486, 0.00624952, 0.        , 0.0062499 , 0.01562681,\n",
       "        0.00312443, 0.        , 0.00312505, 0.00625005, 0.01562572,\n",
       "        0.00312481, 0.0062501 , 0.00625024, 0.00625019, 0.02187433,\n",
       "        0.        , 0.00624909, 0.        , 0.012501  , 0.01562581,\n",
       "        0.00312452, 0.        , 0.01562476, 0.00937586, 0.01562476,\n",
       "        0.00624986, 0.0062499 , 0.00625005, 0.01250439, 0.01562524,\n",
       "        0.        , 0.00312486, 0.00312495, 0.00937519, 0.01717482,\n",
       "        0.00299802, 0.00300188, 0.01059275, 0.01804795, 0.02324767,\n",
       "        0.00312505, 0.00312443, 0.01249919, 0.00524616, 0.01581469,\n",
       "        0.00199862, 0.        , 0.00119944, 0.01250038, 0.03718128,\n",
       "        0.00459728, 0.00499754, 0.00599599, 0.01197815, 0.01939249,\n",
       "        0.00451317, 0.0049974 , 0.0071506 , 0.01379633, 0.02269883,\n",
       "        0.00271554, 0.00159893, 0.00656891, 0.01511827, 0.02140326,\n",
       "        0.00684953, 0.00279832, 0.00290895, 0.0129849 , 0.02191329,\n",
       "        0.00312533, 0.00079856, 0.01097455, 0.01075697, 0.01985221,\n",
       "        0.00379772, 0.00459695, 0.00939388, 0.01319251, 0.01858964,\n",
       "        0.00659604, 0.00398989, 0.008354  , 0.01356864, 0.01901288,\n",
       "        0.00259471, 0.00299869, 0.00379772, 0.01379261, 0.02807212,\n",
       "        0.00259786, 0.00239425, 0.00459628, 0.01818857, 0.02538476,\n",
       "        0.00299826, 0.00399795, 0.01085906, 0.0221869 , 0.02423816,\n",
       "        0.00359807, 0.00489874, 0.01379247, 0.01658964, 0.03438015,\n",
       "        0.00478926, 0.00679646, 0.00879455, 0.02358165, 0.02502918,\n",
       "        0.00299373, 0.00399742, 0.00739565, 0.01439195, 0.02166204,\n",
       "        0.00439663, 0.0049964 , 0.0125927 , 0.01331878, 0.01788092,\n",
       "        0.00472331, 0.00130196, 0.00423198, 0.01533408, 0.02059932,\n",
       "        0.00121174, 0.00419817, 0.00873032, 0.01419134, 0.02340937,\n",
       "        0.01249876, 0.00159912, 0.00824838, 0.00894065, 0.01497698,\n",
       "        0.00319848, 0.00379796, 0.0065237 , 0.01424494, 0.02698216,\n",
       "        0.00519753, 0.00579634, 0.02306371, 0.01772089, 0.08390093,\n",
       "        0.00579214, 0.008395  , 0.00541072, 0.01711698, 0.04455514,\n",
       "        0.00459671, 0.00619311, 0.01131935, 0.01884375, 0.04197607,\n",
       "        0.00579715, 0.00530729, 0.00963249, 0.03271384, 0.02279058,\n",
       "        0.00179515, 0.00937548, 0.0095129 , 0.01430087, 0.03655038,\n",
       "        0.00279813, 0.00359211, 0.00772109, 0.01779552, 0.02994661,\n",
       "        0.00259891, 0.00379434, 0.00759563, 0.01419168, 0.01959176,\n",
       "        0.00280209, 0.00319304, 0.01232429, 0.01254148, 0.01875057,\n",
       "        0.00312471, 0.00624938, 0.00937495, 0.01628613, 0.01789751,\n",
       "        0.00312381, 0.00592523, 0.00624981, 0.01076188, 0.01592765,\n",
       "        0.00319958, 0.00160518, 0.01259198, 0.02279911, 0.02449627,\n",
       "        0.00199842, 0.00578113, 0.01291113, 0.02131414, 0.03063631,\n",
       "        0.00532846, 0.00239825, 0.00476007, 0.01564379, 0.02378602,\n",
       "        0.0023983 , 0.00379758, 0.00759544, 0.01351285, 0.01736798]),\n",
       " 'std_score_time': array([2.09674344e-03, 4.89667804e-04, 1.02585602e-03, 3.15400413e-03,\n",
       "        2.72424595e-03, 1.17170414e-03, 1.49682625e-03, 1.47515931e-03,\n",
       "        2.26848801e-03, 6.39208177e-04, 1.79802099e-03, 1.70998007e-03,\n",
       "        1.36924790e-03, 1.62769642e-03, 2.28690986e-03, 9.78887956e-04,\n",
       "        1.20151131e-03, 2.03875482e-03, 2.70866905e-03, 1.02716627e-03,\n",
       "        4.89123013e-04, 4.89726326e-04, 1.41008416e-03, 1.01527376e-03,\n",
       "        4.33248941e-03, 1.09847951e-03, 6.33026020e-04, 1.71957448e-03,\n",
       "        1.32491467e-03, 1.00330366e-03, 4.88565440e-04, 8.00156684e-04,\n",
       "        1.41543783e-03, 3.77599999e-03, 1.53254907e-03, 1.20058064e-03,\n",
       "        1.35636072e-03, 1.74350467e-03, 1.88140323e-03, 5.31017214e-03,\n",
       "        4.90534911e-04, 1.50020324e-03, 1.60459794e-03, 1.26143636e-03,\n",
       "        6.26506839e-04, 2.51472513e-03, 8.00276236e-04, 1.45480368e-03,\n",
       "        3.12824973e-03, 4.89376575e-04, 4.92064920e-04, 1.41384489e-03,\n",
       "        9.77310431e-04, 4.25955842e-03, 4.17818842e-03, 9.79540341e-04,\n",
       "        1.83168630e-03, 1.04447003e-03, 1.47149175e-03, 1.41299990e-03,\n",
       "        9.80045461e-04, 1.19935219e-03, 2.55858949e-03, 2.29875555e-03,\n",
       "        2.58147010e-03, 7.47666867e-04, 4.89220205e-04, 1.71962031e-03,\n",
       "        1.93442322e-03, 4.94507362e-03, 3.97859013e-03, 2.46510511e-03,\n",
       "        3.97357122e-04, 1.94151459e-03, 2.00717067e-04, 3.99017533e-04,\n",
       "        7.46192586e-04, 4.24876833e-03, 8.81439238e-03, 2.76900662e-03,\n",
       "        1.44993310e-03, 2.29152331e-03, 1.88209349e-03, 1.94142173e-03,\n",
       "        1.01070307e-03, 4.85773338e-04, 3.97518751e-04, 4.92107466e-04,\n",
       "        2.15709724e-03, 2.15401576e-03, 1.60034914e-03, 9.82126860e-04,\n",
       "        2.50499928e-03, 4.44709330e-03, 1.04524161e-03, 7.47907775e-04,\n",
       "        6.25266851e-04, 3.29062736e-03, 3.68795553e-03, 2.07195141e-03,\n",
       "        1.35510222e-03, 1.23665490e-05, 3.99765309e-04, 1.46180812e-03,\n",
       "        1.50462989e-03, 4.00018962e-04, 1.35562247e-03, 6.32183892e-04,\n",
       "        3.98772504e-04, 7.87525621e-03, 9.79111749e-04, 1.35763838e-05,\n",
       "        3.61193301e-03, 1.47330544e-03, 1.16390121e-03, 0.00000000e+00,\n",
       "        6.31655764e-04, 3.94179288e-04, 3.34603729e-03, 3.95233019e-04,\n",
       "        3.99304148e-04, 4.01902119e-04, 4.95755559e-03, 6.07154924e-03,\n",
       "        5.35646481e-03, 5.86831989e-03, 1.54613758e-03, 2.79477031e-03,\n",
       "        7.65471389e-03, 1.96169987e-03, 3.97374339e-04, 6.26244503e-04,\n",
       "        8.01526775e-04, 3.00040603e-03, 4.28224164e-03, 1.20039902e-03,\n",
       "        3.99114724e-04, 7.48125338e-04, 7.46170481e-04, 3.60701855e-03,\n",
       "        4.94773680e-04, 4.56229832e-03, 4.86816901e-04, 6.98757047e-03,\n",
       "        1.62701188e-03, 8.11324097e-06, 3.99733002e-04, 3.60908926e-03,\n",
       "        6.05316057e-03, 1.08735602e-06, 6.24809265e-03, 6.24952316e-03,\n",
       "        7.65430514e-03, 1.15430054e-06, 6.25014308e-03, 7.65430526e-03,\n",
       "        0.00000000e+00, 7.65477226e-03, 9.95665217e-07, 6.25212599e-03,\n",
       "        0.00000000e+00, 6.24933243e-03, 7.65465558e-03, 6.24947554e-03,\n",
       "        6.24949959e-03, 7.65804567e-03, 6.24914169e-03, 7.65469447e-03,\n",
       "        6.25064380e-03, 6.25145801e-03, 6.24895096e-03, 0.00000000e+00,\n",
       "        6.25085831e-03, 1.07261866e-06, 9.30700142e-06, 6.24942780e-03,\n",
       "        0.00000000e+00, 7.65459706e-03, 7.65512266e-03, 1.69930741e-06,\n",
       "        0.00000000e+00, 6.24990463e-03, 7.65469439e-03, 6.25040537e-03,\n",
       "        1.39347450e-06, 6.24036789e-03, 7.65407144e-03, 6.24988096e-03,\n",
       "        6.25011923e-03, 5.30983387e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.25007157e-03, 7.65506425e-03, 6.24861720e-03, 6.24933243e-03,\n",
       "        7.65379894e-03, 6.25019073e-03, 7.65559004e-03, 4.15696997e-07,\n",
       "        6.24961853e-03, 6.24980927e-03, 7.65461653e-03, 7.65523946e-03,\n",
       "        7.00804637e-07, 6.24876022e-03, 6.25019073e-03, 7.65788989e-03,\n",
       "        6.25042930e-03, 8.52787932e-03, 6.24876022e-03, 7.65395464e-03,\n",
       "        7.66044029e-03, 6.25038157e-03, 7.16843432e-07, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.65442186e-03, 7.37264884e-06,\n",
       "        0.00000000e+00, 7.65372106e-03, 6.25000005e-03, 7.65449973e-03,\n",
       "        5.09122765e-07, 6.24904633e-03, 0.00000000e+00, 6.25000000e-03,\n",
       "        9.87993139e-03, 7.65348746e-03, 0.00000000e+00, 6.24933243e-03,\n",
       "        7.65508372e-03, 7.65485014e-03, 9.17214587e-07, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.65430505e-03, 7.65500586e-03, 5.51978917e-07,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.65496700e-03, 6.25019078e-03,\n",
       "        6.24864107e-03, 7.65436353e-03, 6.24952316e-03, 7.65547392e-03,\n",
       "        7.65516182e-03, 1.47280171e-06, 0.00000000e+00, 7.65401305e-03,\n",
       "        6.25019076e-03, 6.24976161e-03, 6.24666232e-03, 6.24923706e-03,\n",
       "        0.00000000e+00, 7.65453874e-03, 6.25002388e-03, 6.24928498e-03,\n",
       "        0.00000000e+00, 6.24923706e-03, 6.24961853e-03, 6.25052455e-03,\n",
       "        3.16297988e-07, 6.25028610e-03, 6.24933243e-03, 7.65453865e-03,\n",
       "        7.65488906e-03, 2.78041453e-07, 6.24856949e-03, 0.00000000e+00,\n",
       "        9.71317291e-04, 6.25028629e-03, 7.42983699e-03, 0.00000000e+00,\n",
       "        7.65652428e-03, 1.66278799e-06, 6.24997618e-03, 9.88106226e-03,\n",
       "        7.65383785e-03, 7.65453886e-03, 5.22348936e-07, 6.25050078e-03,\n",
       "        6.25004770e-03, 6.24923706e-03, 6.25028610e-03, 7.65430509e-03,\n",
       "        6.60393512e-03, 4.28623928e-03, 7.99560547e-04, 5.73638666e-03,\n",
       "        5.76434644e-03, 1.45297057e-03, 2.81293511e-06, 6.24990463e-03,\n",
       "        6.24952316e-03, 7.65500597e-03, 6.11902602e-03, 8.74888988e-06,\n",
       "        6.24895096e-03, 0.00000000e+00, 7.65477225e-03, 7.65500589e-03,\n",
       "        6.28991411e-07, 7.65354584e-03, 6.24933243e-03, 6.24985701e-03,\n",
       "        7.04114752e-03, 1.09361123e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.24804842e-03, 9.48893964e-07, 6.46813391e-07, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.24992848e-03, 7.65430509e-03, 7.59953377e-07,\n",
       "        0.00000000e+00, 7.65446086e-03, 7.64992631e-03, 8.75538468e-06,\n",
       "        6.24880798e-03, 0.00000000e+00, 6.25009537e-03, 6.24980927e-03,\n",
       "        4.15696997e-07, 6.24866490e-03, 6.24885559e-03, 6.25076294e-03,\n",
       "        7.65485013e-03, 7.65508373e-03, 6.24904634e-03, 0.00000000e+00,\n",
       "        7.65372105e-03, 7.65426611e-03, 7.65485012e-03, 1.71528871e-06,\n",
       "        6.24961853e-03, 6.24971390e-03, 6.24983312e-03, 6.25019076e-03,\n",
       "        1.00475824e-06, 6.24904633e-03, 0.00000000e+00, 7.65504480e-03,\n",
       "        7.65523955e-03, 1.89778793e-06, 6.24904633e-03, 7.65448025e-03,\n",
       "        6.25021459e-03, 8.79244276e-07, 5.56082906e-07, 6.24961853e-03,\n",
       "        0.00000000e+00, 7.65492799e-03, 6.24997625e-03, 6.24949934e-03,\n",
       "        0.00000000e+00, 6.25133514e-03, 6.25019073e-03, 6.24923756e-03,\n",
       "        6.24885588e-03, 6.24914169e-03, 7.65453865e-03, 7.65481124e-03,\n",
       "        7.65485017e-03, 6.24907023e-03, 6.24923706e-03, 6.25000000e-03,\n",
       "        6.25028629e-03, 7.65471388e-03, 1.18155591e-06, 0.00000000e+00,\n",
       "        6.25028610e-03, 7.65412985e-03, 7.65422720e-03, 5.91739352e-07,\n",
       "        6.24866486e-03, 7.65424665e-03, 6.24990463e-03, 1.23426238e-06,\n",
       "        6.64157308e-07, 0.00000000e+00, 7.65424664e-03, 6.24914169e-03,\n",
       "        6.25028611e-03, 3.87384339e-07, 6.25047684e-03, 6.24923706e-03,\n",
       "        7.65496692e-03, 7.65500585e-03, 1.13443158e-06, 6.24885559e-03,\n",
       "        0.00000000e+00, 6.25028610e-03, 7.65523948e-03, 7.62939453e-07,\n",
       "        6.24952316e-03, 6.25038147e-03, 6.25028610e-03, 7.65469440e-03,\n",
       "        6.24845038e-03, 6.24933243e-03, 6.24971390e-03, 6.25028610e-03,\n",
       "        7.65531735e-03, 2.24974177e-06, 6.24980927e-03, 6.24818802e-03,\n",
       "        6.25004788e-03, 1.23057250e-06, 6.24876031e-03, 0.00000000e+00,\n",
       "        7.65424669e-03, 6.25045304e-03, 7.65471393e-03, 7.97901179e-07,\n",
       "        0.00000000e+00, 6.25076294e-03, 7.65448026e-03, 7.65469440e-03,\n",
       "        7.65216373e-03, 0.00000000e+00, 0.00000000e+00, 7.65508375e-03,\n",
       "        7.65436345e-03, 9.24621555e-07, 6.24971390e-03, 7.65407146e-03,\n",
       "        0.00000000e+00, 7.65453867e-03, 1.90734863e-07, 6.24885559e-03,\n",
       "        0.00000000e+00, 6.25009537e-03, 7.65471385e-03, 9.77225377e-07,\n",
       "        6.24961853e-03, 7.65477225e-03, 7.65494745e-03, 7.65488905e-03,\n",
       "        7.65276717e-03, 0.00000000e+00, 7.65354597e-03, 0.00000000e+00,\n",
       "        6.25050070e-03, 8.06404806e-07, 6.24904633e-03, 0.00000000e+00,\n",
       "        6.74349576e-07, 7.65535627e-03, 1.08735602e-06, 7.65448025e-03,\n",
       "        7.65453874e-03, 7.65471385e-03, 6.25219874e-03, 1.03375833e-06,\n",
       "        0.00000000e+00, 6.24971390e-03, 6.24990463e-03, 7.65481120e-03,\n",
       "        2.12444813e-03, 1.47434471e-06, 1.67691530e-03, 5.45933772e-03,\n",
       "        1.28856163e-02, 8.69222076e-03, 6.25009537e-03, 6.24885559e-03,\n",
       "        6.24959477e-03, 6.61878404e-03, 4.47602633e-03, 1.09449527e-03,\n",
       "        0.00000000e+00, 2.39887238e-03, 6.25019075e-03, 2.14740234e-02,\n",
       "        1.35562978e-03, 9.58430826e-07, 3.15993760e-03, 6.07584179e-03,\n",
       "        7.59027417e-03, 2.17377927e-03, 2.89683141e-03, 5.30348172e-03,\n",
       "        1.71782951e-03, 6.88110872e-03, 5.43107986e-03, 1.95828176e-03,\n",
       "        3.57686162e-03, 2.20419035e-03, 3.22402971e-03, 7.24793585e-03,\n",
       "        2.39876916e-03, 3.07667358e-03, 6.26203075e-04, 9.57065781e-03,\n",
       "        6.25066757e-03, 1.59711838e-03, 6.23258839e-03, 6.34989617e-03,\n",
       "        6.50321935e-03, 4.00405855e-04, 7.98523940e-04, 2.57549689e-03,\n",
       "        9.79258155e-04, 1.19901538e-03, 7.70626102e-03, 9.11545040e-06,\n",
       "        6.01105249e-03, 7.09569199e-03, 6.77540313e-03, 4.86807887e-04,\n",
       "        2.96533210e-03, 4.74689883e-03, 1.46901004e-03, 3.50909971e-03,\n",
       "        7.99560604e-04, 1.95490642e-03, 3.77047086e-03, 3.76047968e-03,\n",
       "        1.30710231e-02, 1.26463114e-03, 1.00701867e-06, 2.32288916e-03,\n",
       "        4.78830930e-03, 4.14180049e-03, 4.89960833e-04, 9.18718447e-04,\n",
       "        5.59710446e-03, 2.41626064e-03, 1.65637668e-02, 9.84627393e-04,\n",
       "        2.22662768e-03, 4.70449449e-03, 7.07470548e-03, 1.08884130e-02,\n",
       "        6.26318058e-04, 5.13569337e-07, 4.89083870e-04, 1.35579846e-03,\n",
       "        1.88745689e-03, 1.85265103e-03, 1.09453915e-03, 5.81442040e-03,\n",
       "        1.21733132e-03, 3.48081451e-03, 5.55804085e-03, 2.60391235e-03,\n",
       "        3.72538615e-03, 6.14139670e-03, 6.23957723e-03, 1.48420207e-03,\n",
       "        3.99303806e-04, 3.45879587e-03, 4.22772436e-03, 6.55610768e-03,\n",
       "        6.24938070e-03, 1.95851536e-03, 7.04165157e-03, 7.61624420e-03,\n",
       "        3.25799775e-03, 2.22680319e-03, 2.03870263e-03, 5.93750922e-03,\n",
       "        1.47488979e-03, 5.47596519e-03, 1.32611695e-03, 3.36826913e-03,\n",
       "        1.61756833e-02, 4.04962680e-03, 5.64597561e-02, 3.18075198e-03,\n",
       "        4.96090451e-03, 3.86378908e-03, 2.82005968e-03, 4.20973540e-02,\n",
       "        3.07046963e-03, 3.42974283e-03, 3.68443209e-03, 1.66486160e-02,\n",
       "        2.71652518e-02, 3.18589533e-03, 3.60195408e-03, 3.58751434e-03,\n",
       "        1.34065653e-02, 3.70013716e-03, 1.46575316e-03, 7.65504510e-03,\n",
       "        3.18466821e-03, 4.48948247e-03, 2.80035221e-02, 7.47640132e-04,\n",
       "        4.97156207e-04, 2.84509625e-03, 2.68978677e-03, 1.41314061e-02,\n",
       "        4.89999673e-04, 7.41303898e-04, 1.01555896e-03, 2.03860950e-03,\n",
       "        1.02955477e-03, 7.49001738e-04, 1.71467707e-03, 5.41560983e-03,\n",
       "        6.27116276e-03, 6.24947549e-03, 6.24942780e-03, 7.65389627e-03,\n",
       "        7.65461692e-03, 3.50343916e-03, 4.54335229e-03, 6.24761581e-03,\n",
       "        5.62432794e-03, 7.65442190e-03, 5.82264950e-03, 4.18406416e-03,\n",
       "        1.16892376e-03, 1.96595856e-03, 6.52521824e-03, 1.08657030e-02,\n",
       "        1.16849262e-02, 1.67208747e-03, 4.54802269e-03, 5.09851293e-03,\n",
       "        4.92205278e-03, 6.33759670e-03, 5.50225013e-03, 1.95816497e-03,\n",
       "        5.04662749e-03, 7.30037711e-04, 7.24603062e-03, 4.89162101e-04,\n",
       "        4.09937224e-04, 8.00087405e-04, 2.64684316e-03, 2.85265328e-03]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150}],\n",
       " 'split0_test_score': array([0.60416667, 0.65625   , 0.63541667, 0.625     , 0.625     ,\n",
       "        0.64583333, 0.65625   , 0.625     , 0.64583333, 0.60416667,\n",
       "        0.61458333, 0.65625   , 0.61458333, 0.66666667, 0.64583333,\n",
       "        0.65625   , 0.6875    , 0.625     , 0.66666667, 0.625     ,\n",
       "        0.65625   , 0.61458333, 0.64583333, 0.64583333, 0.64583333,\n",
       "        0.625     , 0.65625   , 0.64583333, 0.625     , 0.64583333,\n",
       "        0.66666667, 0.57291667, 0.63541667, 0.66666667, 0.64583333,\n",
       "        0.64583333, 0.69791667, 0.63541667, 0.625     , 0.625     ,\n",
       "        0.6875    , 0.59375   , 0.6875    , 0.65625   , 0.625     ,\n",
       "        0.65625   , 0.64583333, 0.70833333, 0.63541667, 0.625     ,\n",
       "        0.6875    , 0.65625   , 0.625     , 0.61458333, 0.625     ,\n",
       "        0.67708333, 0.65625   , 0.63541667, 0.67708333, 0.64583333,\n",
       "        0.65625   , 0.67708333, 0.60416667, 0.61458333, 0.61458333,\n",
       "        0.5625    , 0.54166667, 0.65625   , 0.59375   , 0.58333333,\n",
       "        0.60416667, 0.64583333, 0.60416667, 0.63541667, 0.625     ,\n",
       "        0.57291667, 0.70833333, 0.61458333, 0.66666667, 0.625     ,\n",
       "        0.625     , 0.64583333, 0.63541667, 0.67708333, 0.61458333,\n",
       "        0.60416667, 0.64583333, 0.67708333, 0.63541667, 0.65625   ,\n",
       "        0.625     , 0.64583333, 0.61458333, 0.63541667, 0.67708333,\n",
       "        0.55208333, 0.60416667, 0.60416667, 0.64583333, 0.63541667,\n",
       "        0.66666667, 0.66666667, 0.63541667, 0.625     , 0.59375   ,\n",
       "        0.64583333, 0.67708333, 0.625     , 0.625     , 0.63541667,\n",
       "        0.61458333, 0.625     , 0.625     , 0.65625   , 0.625     ,\n",
       "        0.64583333, 0.69791667, 0.65625   , 0.63541667, 0.65625   ,\n",
       "        0.70833333, 0.64583333, 0.60416667, 0.59375   , 0.625     ,\n",
       "        0.66666667, 0.63541667, 0.65625   , 0.66666667, 0.625     ,\n",
       "        0.59375   , 0.65625   , 0.59375   , 0.64583333, 0.60416667,\n",
       "        0.64583333, 0.66666667, 0.67708333, 0.625     , 0.64583333,\n",
       "        0.67708333, 0.60416667, 0.57291667, 0.61458333, 0.61458333,\n",
       "        0.64583333, 0.67708333, 0.63541667, 0.61458333, 0.60416667,\n",
       "        0.61458333, 0.69791667, 0.67708333, 0.61458333, 0.64583333,\n",
       "        0.71875   , 0.63541667, 0.61458333, 0.63541667, 0.65625   ,\n",
       "        0.58333333, 0.60416667, 0.63541667, 0.66666667, 0.67708333,\n",
       "        0.6875    , 0.63541667, 0.65625   , 0.64583333, 0.625     ,\n",
       "        0.72916667, 0.67708333, 0.65625   , 0.64583333, 0.66666667,\n",
       "        0.625     , 0.61458333, 0.6875    , 0.625     , 0.65625   ,\n",
       "        0.66666667, 0.625     , 0.625     , 0.64583333, 0.625     ,\n",
       "        0.66666667, 0.67708333, 0.66666667, 0.67708333, 0.67708333,\n",
       "        0.59375   , 0.625     , 0.66666667, 0.64583333, 0.64583333,\n",
       "        0.60416667, 0.69791667, 0.61458333, 0.60416667, 0.67708333,\n",
       "        0.60416667, 0.59375   , 0.63541667, 0.63541667, 0.67708333,\n",
       "        0.6875    , 0.625     , 0.65625   , 0.61458333, 0.64583333,\n",
       "        0.69791667, 0.60416667, 0.66666667, 0.625     , 0.63541667,\n",
       "        0.64583333, 0.625     , 0.63541667, 0.63541667, 0.66666667,\n",
       "        0.59375   , 0.6875    , 0.6875    , 0.625     , 0.61458333,\n",
       "        0.5625    , 0.59375   , 0.59375   , 0.61458333, 0.60416667,\n",
       "        0.72916667, 0.65625   , 0.69791667, 0.65625   , 0.66666667,\n",
       "        0.67708333, 0.63541667, 0.59375   , 0.60416667, 0.65625   ,\n",
       "        0.65625   , 0.59375   , 0.65625   , 0.63541667, 0.625     ,\n",
       "        0.59375   , 0.6875    , 0.70833333, 0.60416667, 0.67708333,\n",
       "        0.60416667, 0.6875    , 0.67708333, 0.64583333, 0.65625   ,\n",
       "        0.60416667, 0.67708333, 0.67708333, 0.69791667, 0.67708333,\n",
       "        0.625     , 0.64583333, 0.63541667, 0.65625   , 0.63541667,\n",
       "        0.61458333, 0.65625   , 0.64583333, 0.65625   , 0.6875    ,\n",
       "        0.70833333, 0.65625   , 0.64583333, 0.64583333, 0.63541667,\n",
       "        0.65625   , 0.69791667, 0.63541667, 0.63541667, 0.66666667,\n",
       "        0.65625   , 0.625     , 0.64583333, 0.61458333, 0.66666667,\n",
       "        0.64583333, 0.65625   , 0.63541667, 0.625     , 0.61458333,\n",
       "        0.73958333, 0.67708333, 0.63541667, 0.65625   , 0.63541667,\n",
       "        0.64583333, 0.625     , 0.61458333, 0.64583333, 0.63541667,\n",
       "        0.6875    , 0.53125   , 0.63541667, 0.61458333, 0.63541667,\n",
       "        0.63541667, 0.67708333, 0.64583333, 0.67708333, 0.61458333,\n",
       "        0.57291667, 0.58333333, 0.625     , 0.64583333, 0.60416667,\n",
       "        0.6875    , 0.625     , 0.67708333, 0.625     , 0.60416667,\n",
       "        0.60416667, 0.64583333, 0.59375   , 0.61458333, 0.63541667,\n",
       "        0.625     , 0.65625   , 0.67708333, 0.64583333, 0.63541667,\n",
       "        0.70833333, 0.63541667, 0.70833333, 0.64583333, 0.64583333,\n",
       "        0.60416667, 0.63541667, 0.625     , 0.71875   , 0.63541667,\n",
       "        0.69791667, 0.63541667, 0.63541667, 0.64583333, 0.66666667,\n",
       "        0.625     , 0.66666667, 0.69791667, 0.60416667, 0.64583333,\n",
       "        0.65625   , 0.64583333, 0.6875    , 0.625     , 0.63541667,\n",
       "        0.63541667, 0.65625   , 0.63541667, 0.625     , 0.63541667,\n",
       "        0.64583333, 0.65625   , 0.60416667, 0.65625   , 0.63541667,\n",
       "        0.66666667, 0.67708333, 0.70833333, 0.60416667, 0.63541667,\n",
       "        0.65625   , 0.58333333, 0.6875    , 0.65625   , 0.625     ,\n",
       "        0.625     , 0.71875   , 0.6875    , 0.63541667, 0.63541667,\n",
       "        0.6875    , 0.57291667, 0.63541667, 0.61458333, 0.66666667,\n",
       "        0.66666667, 0.60416667, 0.70833333, 0.66666667, 0.63541667,\n",
       "        0.64583333, 0.60416667, 0.61458333, 0.65625   , 0.64583333,\n",
       "        0.57291667, 0.57291667, 0.66666667, 0.63541667, 0.60416667,\n",
       "        0.59375   , 0.625     , 0.61458333, 0.66666667, 0.66666667,\n",
       "        0.63541667, 0.6875    , 0.60416667, 0.61458333, 0.64583333,\n",
       "        0.625     , 0.65625   , 0.66666667, 0.66666667, 0.65625   ,\n",
       "        0.67708333, 0.69791667, 0.65625   , 0.63541667, 0.64583333,\n",
       "        0.60416667, 0.60416667, 0.63541667, 0.64583333, 0.64583333,\n",
       "        0.76041667, 0.60416667, 0.625     , 0.625     , 0.65625   ,\n",
       "        0.64583333, 0.63541667, 0.63541667, 0.64583333, 0.64583333,\n",
       "        0.67708333, 0.6875    , 0.625     , 0.65625   , 0.64583333,\n",
       "        0.61458333, 0.625     , 0.61458333, 0.67708333, 0.64583333,\n",
       "        0.625     , 0.71875   , 0.64583333, 0.65625   , 0.61458333,\n",
       "        0.67708333, 0.6875    , 0.65625   , 0.61458333, 0.60416667,\n",
       "        0.61458333, 0.63541667, 0.625     , 0.65625   , 0.64583333,\n",
       "        0.63541667, 0.625     , 0.69791667, 0.65625   , 0.61458333,\n",
       "        0.70833333, 0.69791667, 0.59375   , 0.61458333, 0.65625   ,\n",
       "        0.5625    , 0.625     , 0.64583333, 0.60416667, 0.65625   ,\n",
       "        0.57291667, 0.625     , 0.66666667, 0.67708333, 0.63541667,\n",
       "        0.61458333, 0.61458333, 0.625     , 0.625     , 0.61458333,\n",
       "        0.64583333, 0.64583333, 0.63541667, 0.65625   , 0.625     ,\n",
       "        0.64583333, 0.63541667, 0.61458333, 0.65625   , 0.63541667,\n",
       "        0.64583333, 0.69791667, 0.63541667, 0.64583333, 0.66666667,\n",
       "        0.64583333, 0.625     , 0.59375   , 0.64583333, 0.625     ,\n",
       "        0.67708333, 0.64583333, 0.625     , 0.64583333, 0.66666667,\n",
       "        0.64583333, 0.67708333, 0.64583333, 0.65625   , 0.67708333,\n",
       "        0.69791667, 0.71875   , 0.60416667, 0.63541667, 0.64583333,\n",
       "        0.69791667, 0.625     , 0.63541667, 0.66666667, 0.65625   ,\n",
       "        0.66666667, 0.69791667, 0.66666667, 0.60416667, 0.64583333,\n",
       "        0.61458333, 0.625     , 0.625     , 0.61458333, 0.65625   ,\n",
       "        0.64583333, 0.65625   , 0.65625   , 0.63541667, 0.64583333,\n",
       "        0.61458333, 0.58333333, 0.59375   , 0.65625   , 0.64583333,\n",
       "        0.55208333, 0.61458333, 0.625     , 0.60416667, 0.66666667,\n",
       "        0.72916667, 0.65625   , 0.60416667, 0.64583333, 0.67708333,\n",
       "        0.64583333, 0.66666667, 0.625     , 0.63541667, 0.625     ,\n",
       "        0.63541667, 0.63541667, 0.61458333, 0.60416667, 0.63541667,\n",
       "        0.6875    , 0.63541667, 0.64583333, 0.64583333, 0.66666667,\n",
       "        0.66666667, 0.70833333, 0.66666667, 0.66666667, 0.61458333,\n",
       "        0.60416667, 0.65625   , 0.6875    , 0.63541667, 0.66666667,\n",
       "        0.63541667, 0.65625   , 0.64583333, 0.65625   , 0.63541667,\n",
       "        0.67708333, 0.625     , 0.66666667, 0.69791667, 0.6875    ,\n",
       "        0.63541667, 0.64583333, 0.63541667, 0.65625   , 0.63541667,\n",
       "        0.61458333, 0.64583333, 0.63541667, 0.69791667, 0.64583333,\n",
       "        0.63541667, 0.625     , 0.6875    , 0.65625   , 0.64583333,\n",
       "        0.71875   , 0.63541667, 0.61458333, 0.61458333, 0.61458333,\n",
       "        0.63541667, 0.60416667, 0.65625   , 0.625     , 0.67708333,\n",
       "        0.61458333, 0.60416667, 0.65625   , 0.70833333, 0.64583333,\n",
       "        0.73958333, 0.67708333, 0.63541667, 0.67708333, 0.60416667,\n",
       "        0.67708333, 0.69791667, 0.65625   , 0.625     , 0.625     ,\n",
       "        0.70833333, 0.66666667, 0.65625   , 0.67708333, 0.625     ,\n",
       "        0.63541667, 0.66666667, 0.65625   , 0.625     , 0.65625   ]),\n",
       " 'split1_test_score': array([0.66666667, 0.57291667, 0.64583333, 0.625     , 0.60416667,\n",
       "        0.67708333, 0.625     , 0.65625   , 0.63541667, 0.63541667,\n",
       "        0.625     , 0.61458333, 0.65625   , 0.64583333, 0.63541667,\n",
       "        0.63541667, 0.63541667, 0.67708333, 0.65625   , 0.65625   ,\n",
       "        0.70833333, 0.66666667, 0.625     , 0.625     , 0.6875    ,\n",
       "        0.6875    , 0.65625   , 0.70833333, 0.6875    , 0.69791667,\n",
       "        0.69791667, 0.66666667, 0.69791667, 0.65625   , 0.66666667,\n",
       "        0.625     , 0.66666667, 0.65625   , 0.66666667, 0.64583333,\n",
       "        0.71875   , 0.6875    , 0.69791667, 0.6875    , 0.69791667,\n",
       "        0.70833333, 0.6875    , 0.70833333, 0.64583333, 0.6875    ,\n",
       "        0.72916667, 0.76041667, 0.67708333, 0.66666667, 0.69791667,\n",
       "        0.64583333, 0.6875    , 0.66666667, 0.6875    , 0.67708333,\n",
       "        0.70833333, 0.72916667, 0.6875    , 0.69791667, 0.72916667,\n",
       "        0.58333333, 0.67708333, 0.69791667, 0.69791667, 0.6875    ,\n",
       "        0.70833333, 0.72916667, 0.70833333, 0.65625   , 0.69791667,\n",
       "        0.63541667, 0.6875    , 0.66666667, 0.72916667, 0.66666667,\n",
       "        0.625     , 0.67708333, 0.67708333, 0.59375   , 0.61458333,\n",
       "        0.65625   , 0.625     , 0.625     , 0.65625   , 0.625     ,\n",
       "        0.625     , 0.66666667, 0.67708333, 0.65625   , 0.64583333,\n",
       "        0.65625   , 0.69791667, 0.66666667, 0.66666667, 0.65625   ,\n",
       "        0.66666667, 0.63541667, 0.65625   , 0.625     , 0.65625   ,\n",
       "        0.72916667, 0.70833333, 0.6875    , 0.67708333, 0.67708333,\n",
       "        0.72916667, 0.65625   , 0.6875    , 0.64583333, 0.63541667,\n",
       "        0.69791667, 0.69791667, 0.64583333, 0.67708333, 0.66666667,\n",
       "        0.67708333, 0.6875    , 0.71875   , 0.66666667, 0.69791667,\n",
       "        0.63541667, 0.70833333, 0.64583333, 0.66666667, 0.66666667,\n",
       "        0.69791667, 0.73958333, 0.69791667, 0.69791667, 0.66666667,\n",
       "        0.69791667, 0.70833333, 0.63541667, 0.66666667, 0.65625   ,\n",
       "        0.67708333, 0.70833333, 0.6875    , 0.67708333, 0.69791667,\n",
       "        0.67708333, 0.75      , 0.65625   , 0.72916667, 0.67708333,\n",
       "        0.71875   , 0.64583333, 0.71875   , 0.69791667, 0.6875    ,\n",
       "        0.76041667, 0.70833333, 0.6875    , 0.70833333, 0.67708333,\n",
       "        0.59375   , 0.61458333, 0.61458333, 0.625     , 0.625     ,\n",
       "        0.63541667, 0.64583333, 0.63541667, 0.69791667, 0.625     ,\n",
       "        0.69791667, 0.65625   , 0.63541667, 0.65625   , 0.67708333,\n",
       "        0.66666667, 0.65625   , 0.65625   , 0.63541667, 0.61458333,\n",
       "        0.6875    , 0.61458333, 0.67708333, 0.64583333, 0.66666667,\n",
       "        0.58333333, 0.67708333, 0.70833333, 0.64583333, 0.65625   ,\n",
       "        0.72916667, 0.66666667, 0.70833333, 0.625     , 0.6875    ,\n",
       "        0.65625   , 0.69791667, 0.70833333, 0.66666667, 0.69791667,\n",
       "        0.64583333, 0.66666667, 0.65625   , 0.70833333, 0.69791667,\n",
       "        0.63541667, 0.64583333, 0.67708333, 0.66666667, 0.70833333,\n",
       "        0.77083333, 0.6875    , 0.69791667, 0.6875    , 0.67708333,\n",
       "        0.71875   , 0.72916667, 0.66666667, 0.66666667, 0.73958333,\n",
       "        0.69791667, 0.76041667, 0.72916667, 0.71875   , 0.6875    ,\n",
       "        0.76041667, 0.69791667, 0.72916667, 0.67708333, 0.67708333,\n",
       "        0.72916667, 0.6875    , 0.67708333, 0.6875    , 0.69791667,\n",
       "        0.6875    , 0.6875    , 0.69791667, 0.69791667, 0.6875    ,\n",
       "        0.59375   , 0.64583333, 0.625     , 0.58333333, 0.61458333,\n",
       "        0.60416667, 0.65625   , 0.60416667, 0.63541667, 0.66666667,\n",
       "        0.66666667, 0.67708333, 0.65625   , 0.66666667, 0.64583333,\n",
       "        0.61458333, 0.64583333, 0.64583333, 0.65625   , 0.625     ,\n",
       "        0.71875   , 0.67708333, 0.65625   , 0.67708333, 0.69791667,\n",
       "        0.75      , 0.65625   , 0.76041667, 0.67708333, 0.66666667,\n",
       "        0.67708333, 0.64583333, 0.71875   , 0.66666667, 0.66666667,\n",
       "        0.66666667, 0.65625   , 0.63541667, 0.63541667, 0.6875    ,\n",
       "        0.64583333, 0.70833333, 0.69791667, 0.71875   , 0.69791667,\n",
       "        0.69791667, 0.67708333, 0.70833333, 0.6875    , 0.69791667,\n",
       "        0.67708333, 0.71875   , 0.70833333, 0.6875    , 0.66666667,\n",
       "        0.6875    , 0.6875    , 0.65625   , 0.65625   , 0.71875   ,\n",
       "        0.6875    , 0.73958333, 0.6875    , 0.71875   , 0.67708333,\n",
       "        0.67708333, 0.67708333, 0.65625   , 0.71875   , 0.67708333,\n",
       "        0.71875   , 0.73958333, 0.6875    , 0.6875    , 0.67708333,\n",
       "        0.72916667, 0.71875   , 0.69791667, 0.77083333, 0.71875   ,\n",
       "        0.60416667, 0.625     , 0.65625   , 0.63541667, 0.60416667,\n",
       "        0.6875    , 0.67708333, 0.60416667, 0.64583333, 0.625     ,\n",
       "        0.64583333, 0.65625   , 0.66666667, 0.63541667, 0.65625   ,\n",
       "        0.625     , 0.71875   , 0.64583333, 0.65625   , 0.63541667,\n",
       "        0.59375   , 0.67708333, 0.64583333, 0.65625   , 0.64583333,\n",
       "        0.64583333, 0.6875    , 0.64583333, 0.66666667, 0.66666667,\n",
       "        0.71875   , 0.64583333, 0.6875    , 0.70833333, 0.65625   ,\n",
       "        0.60416667, 0.67708333, 0.64583333, 0.66666667, 0.66666667,\n",
       "        0.70833333, 0.72916667, 0.66666667, 0.63541667, 0.67708333,\n",
       "        0.6875    , 0.73958333, 0.71875   , 0.65625   , 0.66666667,\n",
       "        0.73958333, 0.70833333, 0.625     , 0.65625   , 0.63541667,\n",
       "        0.75      , 0.75      , 0.67708333, 0.69791667, 0.6875    ,\n",
       "        0.6875    , 0.64583333, 0.66666667, 0.65625   , 0.67708333,\n",
       "        0.6875    , 0.71875   , 0.67708333, 0.67708333, 0.66666667,\n",
       "        0.71875   , 0.70833333, 0.67708333, 0.65625   , 0.65625   ,\n",
       "        0.6875    , 0.6875    , 0.66666667, 0.66666667, 0.66666667,\n",
       "        0.65625   , 0.66666667, 0.58333333, 0.61458333, 0.65625   ,\n",
       "        0.66666667, 0.61458333, 0.63541667, 0.63541667, 0.61458333,\n",
       "        0.70833333, 0.66666667, 0.70833333, 0.64583333, 0.64583333,\n",
       "        0.6875    , 0.67708333, 0.63541667, 0.67708333, 0.65625   ,\n",
       "        0.6875    , 0.70833333, 0.63541667, 0.63541667, 0.66666667,\n",
       "        0.65625   , 0.70833333, 0.67708333, 0.65625   , 0.65625   ,\n",
       "        0.60416667, 0.66666667, 0.66666667, 0.66666667, 0.65625   ,\n",
       "        0.6875    , 0.65625   , 0.6875    , 0.65625   , 0.65625   ,\n",
       "        0.64583333, 0.64583333, 0.71875   , 0.66666667, 0.6875    ,\n",
       "        0.76041667, 0.6875    , 0.69791667, 0.66666667, 0.6875    ,\n",
       "        0.58333333, 0.65625   , 0.6875    , 0.65625   , 0.65625   ,\n",
       "        0.6875    , 0.625     , 0.67708333, 0.6875    , 0.64583333,\n",
       "        0.70833333, 0.71875   , 0.69791667, 0.6875    , 0.66666667,\n",
       "        0.67708333, 0.66666667, 0.70833333, 0.63541667, 0.64583333,\n",
       "        0.73958333, 0.71875   , 0.73958333, 0.66666667, 0.66666667,\n",
       "        0.69791667, 0.72916667, 0.64583333, 0.66666667, 0.6875    ,\n",
       "        0.67708333, 0.64583333, 0.66666667, 0.66666667, 0.625     ,\n",
       "        0.71875   , 0.64583333, 0.625     , 0.66666667, 0.65625   ,\n",
       "        0.63541667, 0.59375   , 0.6875    , 0.65625   , 0.67708333,\n",
       "        0.69791667, 0.6875    , 0.66666667, 0.63541667, 0.66666667,\n",
       "        0.64583333, 0.64583333, 0.6875    , 0.64583333, 0.64583333,\n",
       "        0.69791667, 0.67708333, 0.66666667, 0.66666667, 0.65625   ,\n",
       "        0.6875    , 0.6875    , 0.63541667, 0.63541667, 0.66666667,\n",
       "        0.60416667, 0.65625   , 0.6875    , 0.65625   , 0.66666667,\n",
       "        0.6875    , 0.66666667, 0.69791667, 0.69791667, 0.66666667,\n",
       "        0.70833333, 0.71875   , 0.6875    , 0.65625   , 0.66666667,\n",
       "        0.66666667, 0.64583333, 0.64583333, 0.66666667, 0.69791667,\n",
       "        0.65625   , 0.69791667, 0.65625   , 0.66666667, 0.6875    ,\n",
       "        0.67708333, 0.6875    , 0.6875    , 0.6875    , 0.66666667,\n",
       "        0.67708333, 0.6875    , 0.71875   , 0.69791667, 0.67708333,\n",
       "        0.70833333, 0.63541667, 0.65625   , 0.67708333, 0.6875    ,\n",
       "        0.66666667, 0.64583333, 0.70833333, 0.64583333, 0.6875    ,\n",
       "        0.54166667, 0.60416667, 0.625     , 0.625     , 0.60416667,\n",
       "        0.66666667, 0.65625   , 0.65625   , 0.60416667, 0.63541667,\n",
       "        0.61458333, 0.70833333, 0.65625   , 0.63541667, 0.625     ,\n",
       "        0.67708333, 0.61458333, 0.65625   , 0.64583333, 0.625     ,\n",
       "        0.64583333, 0.64583333, 0.65625   , 0.67708333, 0.66666667,\n",
       "        0.59375   , 0.67708333, 0.65625   , 0.65625   , 0.64583333,\n",
       "        0.66666667, 0.61458333, 0.61458333, 0.64583333, 0.67708333,\n",
       "        0.64583333, 0.73958333, 0.65625   , 0.65625   , 0.66666667,\n",
       "        0.69791667, 0.70833333, 0.69791667, 0.65625   , 0.6875    ,\n",
       "        0.66666667, 0.69791667, 0.69791667, 0.65625   , 0.64583333,\n",
       "        0.69791667, 0.6875    , 0.6875    , 0.6875    , 0.70833333,\n",
       "        0.72916667, 0.70833333, 0.65625   , 0.72916667, 0.6875    ,\n",
       "        0.69791667, 0.71875   , 0.69791667, 0.69791667, 0.66666667,\n",
       "        0.73958333, 0.69791667, 0.6875    , 0.66666667, 0.65625   ,\n",
       "        0.70833333, 0.66666667, 0.69791667, 0.69791667, 0.6875    ,\n",
       "        0.71875   , 0.67708333, 0.6875    , 0.65625   , 0.65625   ]),\n",
       " 'split2_test_score': array([0.69791667, 0.66666667, 0.69791667, 0.66666667, 0.72916667,\n",
       "        0.6875    , 0.65625   , 0.6875    , 0.63541667, 0.67708333,\n",
       "        0.6875    , 0.65625   , 0.72916667, 0.70833333, 0.6875    ,\n",
       "        0.66666667, 0.6875    , 0.66666667, 0.63541667, 0.72916667,\n",
       "        0.65625   , 0.64583333, 0.67708333, 0.71875   , 0.69791667,\n",
       "        0.63541667, 0.67708333, 0.67708333, 0.69791667, 0.69791667,\n",
       "        0.625     , 0.63541667, 0.67708333, 0.6875    , 0.69791667,\n",
       "        0.64583333, 0.67708333, 0.6875    , 0.67708333, 0.70833333,\n",
       "        0.63541667, 0.65625   , 0.6875    , 0.71875   , 0.71875   ,\n",
       "        0.60416667, 0.64583333, 0.67708333, 0.66666667, 0.6875    ,\n",
       "        0.6875    , 0.6875    , 0.69791667, 0.6875    , 0.69791667,\n",
       "        0.70833333, 0.69791667, 0.67708333, 0.69791667, 0.70833333,\n",
       "        0.70833333, 0.71875   , 0.67708333, 0.69791667, 0.67708333,\n",
       "        0.65625   , 0.66666667, 0.6875    , 0.69791667, 0.71875   ,\n",
       "        0.65625   , 0.69791667, 0.70833333, 0.6875    , 0.6875    ,\n",
       "        0.59375   , 0.71875   , 0.6875    , 0.67708333, 0.66666667,\n",
       "        0.66666667, 0.70833333, 0.64583333, 0.72916667, 0.67708333,\n",
       "        0.625     , 0.70833333, 0.64583333, 0.69791667, 0.69791667,\n",
       "        0.64583333, 0.66666667, 0.6875    , 0.69791667, 0.65625   ,\n",
       "        0.5625    , 0.6875    , 0.65625   , 0.6875    , 0.69791667,\n",
       "        0.60416667, 0.65625   , 0.66666667, 0.65625   , 0.70833333,\n",
       "        0.66666667, 0.66666667, 0.67708333, 0.70833333, 0.6875    ,\n",
       "        0.64583333, 0.6875    , 0.70833333, 0.71875   , 0.69791667,\n",
       "        0.65625   , 0.6875    , 0.70833333, 0.67708333, 0.69791667,\n",
       "        0.70833333, 0.71875   , 0.65625   , 0.70833333, 0.70833333,\n",
       "        0.55208333, 0.75      , 0.67708333, 0.6875    , 0.69791667,\n",
       "        0.65625   , 0.72916667, 0.71875   , 0.69791667, 0.69791667,\n",
       "        0.66666667, 0.6875    , 0.69791667, 0.66666667, 0.69791667,\n",
       "        0.66666667, 0.73958333, 0.71875   , 0.69791667, 0.6875    ,\n",
       "        0.625     , 0.65625   , 0.625     , 0.67708333, 0.71875   ,\n",
       "        0.63541667, 0.6875    , 0.66666667, 0.66666667, 0.70833333,\n",
       "        0.66666667, 0.76041667, 0.6875    , 0.71875   , 0.67708333,\n",
       "        0.69791667, 0.63541667, 0.6875    , 0.71875   , 0.70833333,\n",
       "        0.63541667, 0.71875   , 0.6875    , 0.6875    , 0.67708333,\n",
       "        0.58333333, 0.69791667, 0.67708333, 0.6875    , 0.66666667,\n",
       "        0.67708333, 0.71875   , 0.65625   , 0.65625   , 0.67708333,\n",
       "        0.66666667, 0.67708333, 0.6875    , 0.6875    , 0.67708333,\n",
       "        0.70833333, 0.65625   , 0.70833333, 0.67708333, 0.69791667,\n",
       "        0.72916667, 0.65625   , 0.65625   , 0.70833333, 0.69791667,\n",
       "        0.70833333, 0.66666667, 0.69791667, 0.6875    , 0.67708333,\n",
       "        0.60416667, 0.67708333, 0.69791667, 0.6875    , 0.69791667,\n",
       "        0.59375   , 0.66666667, 0.66666667, 0.66666667, 0.69791667,\n",
       "        0.67708333, 0.6875    , 0.65625   , 0.71875   , 0.69791667,\n",
       "        0.64583333, 0.66666667, 0.67708333, 0.67708333, 0.6875    ,\n",
       "        0.63541667, 0.71875   , 0.64583333, 0.70833333, 0.70833333,\n",
       "        0.71875   , 0.66666667, 0.73958333, 0.67708333, 0.6875    ,\n",
       "        0.61458333, 0.65625   , 0.72916667, 0.71875   , 0.70833333,\n",
       "        0.58333333, 0.66666667, 0.66666667, 0.6875    , 0.67708333,\n",
       "        0.65625   , 0.66666667, 0.73958333, 0.69791667, 0.70833333,\n",
       "        0.61458333, 0.67708333, 0.69791667, 0.65625   , 0.6875    ,\n",
       "        0.66666667, 0.59375   , 0.70833333, 0.67708333, 0.6875    ,\n",
       "        0.66666667, 0.66666667, 0.64583333, 0.66666667, 0.70833333,\n",
       "        0.67708333, 0.63541667, 0.70833333, 0.6875    , 0.67708333,\n",
       "        0.6875    , 0.67708333, 0.6875    , 0.71875   , 0.70833333,\n",
       "        0.66666667, 0.65625   , 0.6875    , 0.69791667, 0.67708333,\n",
       "        0.65625   , 0.67708333, 0.69791667, 0.69791667, 0.67708333,\n",
       "        0.58333333, 0.625     , 0.71875   , 0.71875   , 0.70833333,\n",
       "        0.64583333, 0.71875   , 0.6875    , 0.69791667, 0.70833333,\n",
       "        0.65625   , 0.69791667, 0.69791667, 0.67708333, 0.65625   ,\n",
       "        0.63541667, 0.66666667, 0.66666667, 0.69791667, 0.6875    ,\n",
       "        0.73958333, 0.64583333, 0.66666667, 0.72916667, 0.65625   ,\n",
       "        0.65625   , 0.6875    , 0.63541667, 0.6875    , 0.65625   ,\n",
       "        0.6875    , 0.70833333, 0.65625   , 0.6875    , 0.70833333,\n",
       "        0.67708333, 0.6875    , 0.6875    , 0.70833333, 0.6875    ,\n",
       "        0.625     , 0.61458333, 0.63541667, 0.71875   , 0.69791667,\n",
       "        0.59375   , 0.67708333, 0.65625   , 0.69791667, 0.67708333,\n",
       "        0.63541667, 0.65625   , 0.66666667, 0.6875    , 0.69791667,\n",
       "        0.59375   , 0.6875    , 0.69791667, 0.67708333, 0.67708333,\n",
       "        0.64583333, 0.66666667, 0.65625   , 0.67708333, 0.67708333,\n",
       "        0.61458333, 0.70833333, 0.66666667, 0.67708333, 0.6875    ,\n",
       "        0.59375   , 0.66666667, 0.6875    , 0.69791667, 0.6875    ,\n",
       "        0.61458333, 0.63541667, 0.66666667, 0.69791667, 0.66666667,\n",
       "        0.60416667, 0.6875    , 0.69791667, 0.70833333, 0.66666667,\n",
       "        0.625     , 0.63541667, 0.63541667, 0.67708333, 0.6875    ,\n",
       "        0.70833333, 0.625     , 0.71875   , 0.66666667, 0.65625   ,\n",
       "        0.67708333, 0.6875    , 0.67708333, 0.6875    , 0.67708333,\n",
       "        0.58333333, 0.61458333, 0.70833333, 0.66666667, 0.6875    ,\n",
       "        0.6875    , 0.61458333, 0.67708333, 0.72916667, 0.66666667,\n",
       "        0.63541667, 0.63541667, 0.67708333, 0.6875    , 0.69791667,\n",
       "        0.69791667, 0.625     , 0.6875    , 0.67708333, 0.69791667,\n",
       "        0.625     , 0.65625   , 0.65625   , 0.6875    , 0.69791667,\n",
       "        0.625     , 0.70833333, 0.65625   , 0.6875    , 0.6875    ,\n",
       "        0.625     , 0.63541667, 0.66666667, 0.64583333, 0.71875   ,\n",
       "        0.63541667, 0.67708333, 0.61458333, 0.6875    , 0.6875    ,\n",
       "        0.625     , 0.6875    , 0.70833333, 0.6875    , 0.6875    ,\n",
       "        0.66666667, 0.71875   , 0.67708333, 0.66666667, 0.69791667,\n",
       "        0.63541667, 0.64583333, 0.67708333, 0.65625   , 0.67708333,\n",
       "        0.63541667, 0.67708333, 0.70833333, 0.66666667, 0.66666667,\n",
       "        0.69791667, 0.69791667, 0.65625   , 0.67708333, 0.66666667,\n",
       "        0.66666667, 0.63541667, 0.67708333, 0.63541667, 0.6875    ,\n",
       "        0.60416667, 0.67708333, 0.6875    , 0.65625   , 0.66666667,\n",
       "        0.69791667, 0.66666667, 0.69791667, 0.69791667, 0.6875    ,\n",
       "        0.71875   , 0.66666667, 0.66666667, 0.66666667, 0.69791667,\n",
       "        0.6875    , 0.67708333, 0.65625   , 0.66666667, 0.6875    ,\n",
       "        0.65625   , 0.66666667, 0.66666667, 0.63541667, 0.6875    ,\n",
       "        0.70833333, 0.65625   , 0.6875    , 0.6875    , 0.69791667,\n",
       "        0.60416667, 0.59375   , 0.70833333, 0.67708333, 0.65625   ,\n",
       "        0.61458333, 0.69791667, 0.65625   , 0.71875   , 0.6875    ,\n",
       "        0.69791667, 0.59375   , 0.70833333, 0.69791667, 0.6875    ,\n",
       "        0.67708333, 0.66666667, 0.65625   , 0.66666667, 0.66666667,\n",
       "        0.64583333, 0.60416667, 0.67708333, 0.69791667, 0.67708333,\n",
       "        0.625     , 0.6875    , 0.65625   , 0.6875    , 0.66666667,\n",
       "        0.59375   , 0.6875    , 0.69791667, 0.65625   , 0.71875   ,\n",
       "        0.67708333, 0.69791667, 0.69791667, 0.66666667, 0.67708333,\n",
       "        0.61458333, 0.67708333, 0.69791667, 0.67708333, 0.71875   ,\n",
       "        0.58333333, 0.6875    , 0.66666667, 0.6875    , 0.6875    ,\n",
       "        0.67708333, 0.65625   , 0.67708333, 0.65625   , 0.69791667,\n",
       "        0.65625   , 0.69791667, 0.66666667, 0.66666667, 0.65625   ,\n",
       "        0.72916667, 0.67708333, 0.6875    , 0.69791667, 0.6875    ,\n",
       "        0.6875    , 0.66666667, 0.66666667, 0.70833333, 0.69791667,\n",
       "        0.63541667, 0.69791667, 0.66666667, 0.65625   , 0.65625   ,\n",
       "        0.60416667, 0.69791667, 0.64583333, 0.69791667, 0.66666667,\n",
       "        0.67708333, 0.70833333, 0.69791667, 0.6875    , 0.6875    ,\n",
       "        0.66666667, 0.65625   , 0.69791667, 0.6875    , 0.66666667,\n",
       "        0.625     , 0.72916667, 0.67708333, 0.6875    , 0.71875   ,\n",
       "        0.60416667, 0.71875   , 0.66666667, 0.71875   , 0.64583333,\n",
       "        0.72916667, 0.6875    , 0.6875    , 0.69791667, 0.70833333,\n",
       "        0.65625   , 0.71875   , 0.66666667, 0.69791667, 0.67708333,\n",
       "        0.625     , 0.65625   , 0.64583333, 0.69791667, 0.66666667,\n",
       "        0.6875    , 0.65625   , 0.65625   , 0.66666667, 0.70833333,\n",
       "        0.65625   , 0.63541667, 0.65625   , 0.6875    , 0.67708333,\n",
       "        0.66666667, 0.70833333, 0.6875    , 0.70833333, 0.69791667,\n",
       "        0.65625   , 0.6875    , 0.72916667, 0.66666667, 0.6875    ,\n",
       "        0.64583333, 0.67708333, 0.66666667, 0.6875    , 0.6875    ,\n",
       "        0.63541667, 0.66666667, 0.67708333, 0.66666667, 0.69791667,\n",
       "        0.625     , 0.6875    , 0.66666667, 0.66666667, 0.66666667,\n",
       "        0.6875    , 0.65625   , 0.67708333, 0.69791667, 0.69791667,\n",
       "        0.65625   , 0.6875    , 0.70833333, 0.6875    , 0.6875    ]),\n",
       " 'split3_test_score': array([0.69791667, 0.75      , 0.76041667, 0.71875   , 0.76041667,\n",
       "        0.70833333, 0.71875   , 0.72916667, 0.76041667, 0.73958333,\n",
       "        0.76041667, 0.78125   , 0.71875   , 0.79166667, 0.80208333,\n",
       "        0.72916667, 0.76041667, 0.79166667, 0.77083333, 0.76041667,\n",
       "        0.72916667, 0.79166667, 0.72916667, 0.80208333, 0.76041667,\n",
       "        0.64583333, 0.75      , 0.77083333, 0.75      , 0.78125   ,\n",
       "        0.76041667, 0.73958333, 0.80208333, 0.71875   , 0.77083333,\n",
       "        0.72916667, 0.72916667, 0.77083333, 0.72916667, 0.71875   ,\n",
       "        0.70833333, 0.72916667, 0.71875   , 0.75      , 0.76041667,\n",
       "        0.69791667, 0.71875   , 0.75      , 0.72916667, 0.77083333,\n",
       "        0.71875   , 0.71875   , 0.82291667, 0.73958333, 0.76041667,\n",
       "        0.69791667, 0.75      , 0.73958333, 0.76041667, 0.77083333,\n",
       "        0.73958333, 0.72916667, 0.76041667, 0.72916667, 0.76041667,\n",
       "        0.64583333, 0.71875   , 0.67708333, 0.72916667, 0.77083333,\n",
       "        0.79166667, 0.78125   , 0.71875   , 0.73958333, 0.70833333,\n",
       "        0.66666667, 0.76041667, 0.78125   , 0.76041667, 0.75      ,\n",
       "        0.6875    , 0.66666667, 0.75      , 0.75      , 0.70833333,\n",
       "        0.67708333, 0.76041667, 0.76041667, 0.77083333, 0.76041667,\n",
       "        0.71875   , 0.73958333, 0.69791667, 0.80208333, 0.77083333,\n",
       "        0.79166667, 0.76041667, 0.73958333, 0.73958333, 0.78125   ,\n",
       "        0.76041667, 0.72916667, 0.75      , 0.76041667, 0.72916667,\n",
       "        0.73958333, 0.79166667, 0.73958333, 0.77083333, 0.73958333,\n",
       "        0.71875   , 0.72916667, 0.78125   , 0.8125    , 0.72916667,\n",
       "        0.8125    , 0.78125   , 0.70833333, 0.76041667, 0.77083333,\n",
       "        0.73958333, 0.79166667, 0.71875   , 0.77083333, 0.71875   ,\n",
       "        0.73958333, 0.73958333, 0.75      , 0.8125    , 0.70833333,\n",
       "        0.78125   , 0.82291667, 0.72916667, 0.78125   , 0.75      ,\n",
       "        0.79166667, 0.72916667, 0.77083333, 0.76041667, 0.76041667,\n",
       "        0.77083333, 0.73958333, 0.72916667, 0.73958333, 0.73958333,\n",
       "        0.77083333, 0.77083333, 0.70833333, 0.73958333, 0.78125   ,\n",
       "        0.61458333, 0.77083333, 0.73958333, 0.71875   , 0.71875   ,\n",
       "        0.77083333, 0.73958333, 0.77083333, 0.75      , 0.77083333,\n",
       "        0.70833333, 0.72916667, 0.71875   , 0.73958333, 0.76041667,\n",
       "        0.71875   , 0.76041667, 0.70833333, 0.75      , 0.73958333,\n",
       "        0.75      , 0.73958333, 0.77083333, 0.77083333, 0.73958333,\n",
       "        0.72916667, 0.76041667, 0.76041667, 0.78125   , 0.75      ,\n",
       "        0.75      , 0.6875    , 0.70833333, 0.80208333, 0.72916667,\n",
       "        0.77083333, 0.76041667, 0.73958333, 0.75      , 0.73958333,\n",
       "        0.69791667, 0.76041667, 0.77083333, 0.76041667, 0.79166667,\n",
       "        0.70833333, 0.70833333, 0.77083333, 0.77083333, 0.77083333,\n",
       "        0.76041667, 0.71875   , 0.76041667, 0.6875    , 0.76041667,\n",
       "        0.72916667, 0.76041667, 0.73958333, 0.72916667, 0.72916667,\n",
       "        0.72916667, 0.71875   , 0.75      , 0.76041667, 0.78125   ,\n",
       "        0.69791667, 0.73958333, 0.75      , 0.77083333, 0.75      ,\n",
       "        0.75      , 0.73958333, 0.70833333, 0.76041667, 0.72916667,\n",
       "        0.72916667, 0.73958333, 0.75      , 0.75      , 0.73958333,\n",
       "        0.71875   , 0.73958333, 0.78125   , 0.72916667, 0.71875   ,\n",
       "        0.6875    , 0.75      , 0.77083333, 0.76041667, 0.77083333,\n",
       "        0.67708333, 0.71875   , 0.73958333, 0.71875   , 0.75      ,\n",
       "        0.75      , 0.71875   , 0.78125   , 0.77083333, 0.70833333,\n",
       "        0.71875   , 0.76041667, 0.75      , 0.73958333, 0.78125   ,\n",
       "        0.71875   , 0.69791667, 0.78125   , 0.78125   , 0.78125   ,\n",
       "        0.72916667, 0.79166667, 0.80208333, 0.78125   , 0.78125   ,\n",
       "        0.6875    , 0.72916667, 0.75      , 0.73958333, 0.79166667,\n",
       "        0.79166667, 0.76041667, 0.77083333, 0.75      , 0.71875   ,\n",
       "        0.71875   , 0.70833333, 0.76041667, 0.78125   , 0.77083333,\n",
       "        0.64583333, 0.77083333, 0.75      , 0.76041667, 0.76041667,\n",
       "        0.6875    , 0.72916667, 0.71875   , 0.77083333, 0.75      ,\n",
       "        0.72916667, 0.77083333, 0.78125   , 0.79166667, 0.75      ,\n",
       "        0.70833333, 0.77083333, 0.76041667, 0.73958333, 0.77083333,\n",
       "        0.64583333, 0.75      , 0.72916667, 0.72916667, 0.73958333,\n",
       "        0.73958333, 0.70833333, 0.76041667, 0.72916667, 0.71875   ,\n",
       "        0.70833333, 0.75      , 0.73958333, 0.70833333, 0.75      ,\n",
       "        0.77083333, 0.78125   , 0.77083333, 0.71875   , 0.78125   ,\n",
       "        0.625     , 0.75      , 0.8125    , 0.73958333, 0.77083333,\n",
       "        0.67708333, 0.73958333, 0.76041667, 0.76041667, 0.73958333,\n",
       "        0.71875   , 0.76041667, 0.69791667, 0.73958333, 0.75      ,\n",
       "        0.65625   , 0.70833333, 0.73958333, 0.75      , 0.76041667,\n",
       "        0.72916667, 0.77083333, 0.76041667, 0.76041667, 0.77083333,\n",
       "        0.77083333, 0.79166667, 0.77083333, 0.8125    , 0.75      ,\n",
       "        0.6875    , 0.73958333, 0.75      , 0.76041667, 0.77083333,\n",
       "        0.6875    , 0.73958333, 0.75      , 0.76041667, 0.76041667,\n",
       "        0.76041667, 0.78125   , 0.77083333, 0.77083333, 0.75      ,\n",
       "        0.69791667, 0.77083333, 0.77083333, 0.75      , 0.77083333,\n",
       "        0.66666667, 0.73958333, 0.73958333, 0.77083333, 0.75      ,\n",
       "        0.73958333, 0.76041667, 0.72916667, 0.72916667, 0.72916667,\n",
       "        0.69791667, 0.75      , 0.71875   , 0.72916667, 0.73958333,\n",
       "        0.76041667, 0.71875   , 0.71875   , 0.77083333, 0.78125   ,\n",
       "        0.78125   , 0.73958333, 0.73958333, 0.76041667, 0.78125   ,\n",
       "        0.66666667, 0.77083333, 0.75      , 0.72916667, 0.71875   ,\n",
       "        0.65625   , 0.70833333, 0.6875    , 0.75      , 0.75      ,\n",
       "        0.71875   , 0.73958333, 0.73958333, 0.72916667, 0.77083333,\n",
       "        0.67708333, 0.69791667, 0.77083333, 0.76041667, 0.79166667,\n",
       "        0.77083333, 0.73958333, 0.79166667, 0.79166667, 0.77083333,\n",
       "        0.73958333, 0.71875   , 0.73958333, 0.77083333, 0.79166667,\n",
       "        0.72916667, 0.76041667, 0.78125   , 0.78125   , 0.78125   ,\n",
       "        0.70833333, 0.72916667, 0.8125    , 0.78125   , 0.73958333,\n",
       "        0.70833333, 0.75      , 0.73958333, 0.80208333, 0.79166667,\n",
       "        0.8125    , 0.75      , 0.73958333, 0.76041667, 0.73958333,\n",
       "        0.71875   , 0.72916667, 0.71875   , 0.75      , 0.71875   ,\n",
       "        0.6875    , 0.70833333, 0.77083333, 0.76041667, 0.77083333,\n",
       "        0.75      , 0.78125   , 0.75      , 0.73958333, 0.70833333,\n",
       "        0.72916667, 0.69791667, 0.71875   , 0.75      , 0.73958333,\n",
       "        0.70833333, 0.72916667, 0.72916667, 0.75      , 0.72916667,\n",
       "        0.78125   , 0.76041667, 0.72916667, 0.72916667, 0.73958333,\n",
       "        0.71875   , 0.76041667, 0.76041667, 0.78125   , 0.76041667,\n",
       "        0.72916667, 0.76041667, 0.70833333, 0.69791667, 0.75      ,\n",
       "        0.72916667, 0.75      , 0.80208333, 0.77083333, 0.77083333,\n",
       "        0.70833333, 0.72916667, 0.76041667, 0.77083333, 0.75      ,\n",
       "        0.72916667, 0.70833333, 0.73958333, 0.75      , 0.76041667,\n",
       "        0.69791667, 0.76041667, 0.75      , 0.73958333, 0.79166667,\n",
       "        0.70833333, 0.69791667, 0.77083333, 0.77083333, 0.73958333,\n",
       "        0.69791667, 0.76041667, 0.77083333, 0.77083333, 0.75      ,\n",
       "        0.6875    , 0.71875   , 0.79166667, 0.77083333, 0.76041667,\n",
       "        0.76041667, 0.73958333, 0.75      , 0.75      , 0.76041667,\n",
       "        0.6875    , 0.76041667, 0.76041667, 0.76041667, 0.73958333,\n",
       "        0.67708333, 0.79166667, 0.75      , 0.73958333, 0.72916667,\n",
       "        0.73958333, 0.70833333, 0.75      , 0.76041667, 0.71875   ,\n",
       "        0.625     , 0.79166667, 0.79166667, 0.78125   , 0.76041667,\n",
       "        0.6875    , 0.6875    , 0.75      , 0.75      , 0.77083333,\n",
       "        0.79166667, 0.75      , 0.75      , 0.73958333, 0.73958333,\n",
       "        0.70833333, 0.72916667, 0.71875   , 0.79166667, 0.76041667,\n",
       "        0.72916667, 0.625     , 0.75      , 0.71875   , 0.75      ,\n",
       "        0.67708333, 0.75      , 0.79166667, 0.78125   , 0.75      ,\n",
       "        0.76041667, 0.69791667, 0.71875   , 0.75      , 0.73958333,\n",
       "        0.73958333, 0.77083333, 0.76041667, 0.75      , 0.77083333,\n",
       "        0.72916667, 0.72916667, 0.76041667, 0.76041667, 0.75      ,\n",
       "        0.70833333, 0.8125    , 0.75      , 0.77083333, 0.79166667,\n",
       "        0.69791667, 0.76041667, 0.71875   , 0.75      , 0.76041667,\n",
       "        0.76041667, 0.77083333, 0.77083333, 0.78125   , 0.77083333,\n",
       "        0.76041667, 0.76041667, 0.76041667, 0.75      , 0.72916667,\n",
       "        0.76041667, 0.76041667, 0.76041667, 0.76041667, 0.72916667,\n",
       "        0.60416667, 0.78125   , 0.75      , 0.77083333, 0.78125   ,\n",
       "        0.72916667, 0.76041667, 0.73958333, 0.77083333, 0.78125   ,\n",
       "        0.78125   , 0.76041667, 0.77083333, 0.76041667, 0.72916667,\n",
       "        0.69791667, 0.71875   , 0.73958333, 0.77083333, 0.77083333,\n",
       "        0.75      , 0.71875   , 0.75      , 0.73958333, 0.71875   ,\n",
       "        0.71875   , 0.71875   , 0.71875   , 0.75      , 0.76041667]),\n",
       " 'split4_test_score': array([0.66666667, 0.64583333, 0.69791667, 0.66666667, 0.75      ,\n",
       "        0.6875    , 0.625     , 0.6875    , 0.71875   , 0.6875    ,\n",
       "        0.69791667, 0.73958333, 0.70833333, 0.69791667, 0.71875   ,\n",
       "        0.72916667, 0.71875   , 0.6875    , 0.71875   , 0.71875   ,\n",
       "        0.66666667, 0.6875    , 0.70833333, 0.75      , 0.70833333,\n",
       "        0.66666667, 0.70833333, 0.72916667, 0.71875   , 0.71875   ,\n",
       "        0.70833333, 0.69791667, 0.71875   , 0.71875   , 0.70833333,\n",
       "        0.71875   , 0.70833333, 0.72916667, 0.69791667, 0.71875   ,\n",
       "        0.71875   , 0.6875    , 0.70833333, 0.72916667, 0.70833333,\n",
       "        0.64583333, 0.67708333, 0.75      , 0.71875   , 0.69791667,\n",
       "        0.71875   , 0.75      , 0.6875    , 0.70833333, 0.69791667,\n",
       "        0.73958333, 0.63541667, 0.72916667, 0.72916667, 0.73958333,\n",
       "        0.61458333, 0.67708333, 0.79166667, 0.71875   , 0.72916667,\n",
       "        0.66666667, 0.72916667, 0.64583333, 0.70833333, 0.72916667,\n",
       "        0.71875   , 0.67708333, 0.69791667, 0.65625   , 0.6875    ,\n",
       "        0.625     , 0.63541667, 0.67708333, 0.67708333, 0.67708333,\n",
       "        0.57291667, 0.67708333, 0.67708333, 0.72916667, 0.71875   ,\n",
       "        0.71875   , 0.6875    , 0.70833333, 0.67708333, 0.67708333,\n",
       "        0.64583333, 0.70833333, 0.75      , 0.67708333, 0.71875   ,\n",
       "        0.69791667, 0.72916667, 0.72916667, 0.71875   , 0.67708333,\n",
       "        0.66666667, 0.70833333, 0.72916667, 0.73958333, 0.72916667,\n",
       "        0.63541667, 0.69791667, 0.75      , 0.71875   , 0.72916667,\n",
       "        0.70833333, 0.71875   , 0.72916667, 0.75      , 0.72916667,\n",
       "        0.63541667, 0.6875    , 0.6875    , 0.73958333, 0.70833333,\n",
       "        0.67708333, 0.71875   , 0.73958333, 0.70833333, 0.73958333,\n",
       "        0.69791667, 0.71875   , 0.71875   , 0.73958333, 0.70833333,\n",
       "        0.67708333, 0.71875   , 0.71875   , 0.72916667, 0.72916667,\n",
       "        0.64583333, 0.63541667, 0.69791667, 0.71875   , 0.71875   ,\n",
       "        0.69791667, 0.64583333, 0.75      , 0.75      , 0.6875    ,\n",
       "        0.72916667, 0.70833333, 0.76041667, 0.63541667, 0.70833333,\n",
       "        0.75      , 0.6875    , 0.70833333, 0.73958333, 0.71875   ,\n",
       "        0.79166667, 0.67708333, 0.59375   , 0.70833333, 0.70833333,\n",
       "        0.64583333, 0.72916667, 0.70833333, 0.71875   , 0.71875   ,\n",
       "        0.66666667, 0.71875   , 0.69791667, 0.72916667, 0.71875   ,\n",
       "        0.6875    , 0.6875    , 0.67708333, 0.6875    , 0.71875   ,\n",
       "        0.69791667, 0.70833333, 0.71875   , 0.66666667, 0.67708333,\n",
       "        0.6875    , 0.71875   , 0.71875   , 0.71875   , 0.72916667,\n",
       "        0.71875   , 0.71875   , 0.70833333, 0.70833333, 0.70833333,\n",
       "        0.6875    , 0.66666667, 0.70833333, 0.71875   , 0.70833333,\n",
       "        0.73958333, 0.6875    , 0.71875   , 0.69791667, 0.72916667,\n",
       "        0.67708333, 0.69791667, 0.6875    , 0.71875   , 0.70833333,\n",
       "        0.72916667, 0.67708333, 0.65625   , 0.67708333, 0.69791667,\n",
       "        0.73958333, 0.6875    , 0.70833333, 0.69791667, 0.70833333,\n",
       "        0.67708333, 0.72916667, 0.71875   , 0.69791667, 0.75      ,\n",
       "        0.70833333, 0.69791667, 0.65625   , 0.71875   , 0.76041667,\n",
       "        0.71875   , 0.72916667, 0.6875    , 0.71875   , 0.73958333,\n",
       "        0.65625   , 0.73958333, 0.70833333, 0.67708333, 0.72916667,\n",
       "        0.63541667, 0.6875    , 0.71875   , 0.66666667, 0.69791667,\n",
       "        0.60416667, 0.6875    , 0.70833333, 0.70833333, 0.69791667,\n",
       "        0.67708333, 0.75      , 0.69791667, 0.69791667, 0.70833333,\n",
       "        0.69791667, 0.72916667, 0.71875   , 0.69791667, 0.70833333,\n",
       "        0.69791667, 0.67708333, 0.6875    , 0.70833333, 0.69791667,\n",
       "        0.75      , 0.69791667, 0.67708333, 0.70833333, 0.72916667,\n",
       "        0.71875   , 0.6875    , 0.72916667, 0.70833333, 0.70833333,\n",
       "        0.65625   , 0.63541667, 0.6875    , 0.70833333, 0.69791667,\n",
       "        0.69791667, 0.75      , 0.71875   , 0.73958333, 0.71875   ,\n",
       "        0.625     , 0.64583333, 0.72916667, 0.67708333, 0.71875   ,\n",
       "        0.75      , 0.71875   , 0.70833333, 0.73958333, 0.69791667,\n",
       "        0.67708333, 0.78125   , 0.64583333, 0.71875   , 0.66666667,\n",
       "        0.71875   , 0.70833333, 0.67708333, 0.76041667, 0.73958333,\n",
       "        0.67708333, 0.71875   , 0.71875   , 0.71875   , 0.70833333,\n",
       "        0.65625   , 0.6875    , 0.72916667, 0.69791667, 0.67708333,\n",
       "        0.71875   , 0.64583333, 0.69791667, 0.6875    , 0.67708333,\n",
       "        0.75      , 0.6875    , 0.72916667, 0.75      , 0.66666667,\n",
       "        0.64583333, 0.625     , 0.70833333, 0.70833333, 0.67708333,\n",
       "        0.78125   , 0.625     , 0.69791667, 0.71875   , 0.6875    ,\n",
       "        0.6875    , 0.65625   , 0.71875   , 0.69791667, 0.71875   ,\n",
       "        0.77083333, 0.76041667, 0.70833333, 0.71875   , 0.69791667,\n",
       "        0.69791667, 0.6875    , 0.72916667, 0.72916667, 0.70833333,\n",
       "        0.71875   , 0.71875   , 0.72916667, 0.72916667, 0.72916667,\n",
       "        0.70833333, 0.67708333, 0.70833333, 0.72916667, 0.70833333,\n",
       "        0.72916667, 0.70833333, 0.70833333, 0.6875    , 0.70833333,\n",
       "        0.64583333, 0.71875   , 0.71875   , 0.72916667, 0.72916667,\n",
       "        0.65625   , 0.6875    , 0.70833333, 0.72916667, 0.70833333,\n",
       "        0.71875   , 0.73958333, 0.64583333, 0.71875   , 0.71875   ,\n",
       "        0.69791667, 0.76041667, 0.75      , 0.71875   , 0.71875   ,\n",
       "        0.66666667, 0.64583333, 0.72916667, 0.78125   , 0.72916667,\n",
       "        0.61458333, 0.70833333, 0.65625   , 0.625     , 0.72916667,\n",
       "        0.58333333, 0.67708333, 0.71875   , 0.72916667, 0.6875    ,\n",
       "        0.61458333, 0.63541667, 0.73958333, 0.70833333, 0.6875    ,\n",
       "        0.6875    , 0.69791667, 0.6875    , 0.66666667, 0.70833333,\n",
       "        0.72916667, 0.58333333, 0.69791667, 0.71875   , 0.70833333,\n",
       "        0.65625   , 0.64583333, 0.6875    , 0.70833333, 0.69791667,\n",
       "        0.72916667, 0.73958333, 0.6875    , 0.70833333, 0.71875   ,\n",
       "        0.67708333, 0.69791667, 0.71875   , 0.72916667, 0.69791667,\n",
       "        0.66666667, 0.69791667, 0.6875    , 0.72916667, 0.71875   ,\n",
       "        0.69791667, 0.69791667, 0.6875    , 0.6875    , 0.6875    ,\n",
       "        0.6875    , 0.71875   , 0.70833333, 0.72916667, 0.73958333,\n",
       "        0.67708333, 0.6875    , 0.69791667, 0.70833333, 0.72916667,\n",
       "        0.73958333, 0.73958333, 0.69791667, 0.71875   , 0.70833333,\n",
       "        0.70833333, 0.69791667, 0.71875   , 0.73958333, 0.72916667,\n",
       "        0.625     , 0.71875   , 0.69791667, 0.69791667, 0.70833333,\n",
       "        0.51041667, 0.64583333, 0.70833333, 0.69791667, 0.72916667,\n",
       "        0.57291667, 0.69791667, 0.66666667, 0.75      , 0.75      ,\n",
       "        0.77083333, 0.73958333, 0.66666667, 0.66666667, 0.72916667,\n",
       "        0.66666667, 0.71875   , 0.72916667, 0.6875    , 0.69791667,\n",
       "        0.72916667, 0.65625   , 0.70833333, 0.69791667, 0.70833333,\n",
       "        0.70833333, 0.69791667, 0.70833333, 0.70833333, 0.71875   ,\n",
       "        0.65625   , 0.69791667, 0.70833333, 0.70833333, 0.6875    ,\n",
       "        0.71875   , 0.69791667, 0.69791667, 0.72916667, 0.67708333,\n",
       "        0.72916667, 0.71875   , 0.72916667, 0.75      , 0.70833333,\n",
       "        0.71875   , 0.67708333, 0.6875    , 0.76041667, 0.69791667,\n",
       "        0.72916667, 0.72916667, 0.73958333, 0.71875   , 0.72916667,\n",
       "        0.69791667, 0.70833333, 0.76041667, 0.71875   , 0.72916667,\n",
       "        0.67708333, 0.72916667, 0.6875    , 0.69791667, 0.72916667,\n",
       "        0.70833333, 0.6875    , 0.70833333, 0.72916667, 0.70833333,\n",
       "        0.66666667, 0.69791667, 0.71875   , 0.6875    , 0.73958333,\n",
       "        0.69791667, 0.73958333, 0.70833333, 0.71875   , 0.70833333,\n",
       "        0.73958333, 0.69791667, 0.70833333, 0.71875   , 0.63541667,\n",
       "        0.70833333, 0.6875    , 0.71875   , 0.66666667, 0.70833333,\n",
       "        0.70833333, 0.71875   , 0.67708333, 0.71875   , 0.70833333,\n",
       "        0.72916667, 0.58333333, 0.75      , 0.67708333, 0.67708333,\n",
       "        0.69791667, 0.67708333, 0.70833333, 0.69791667, 0.71875   ,\n",
       "        0.66666667, 0.69791667, 0.6875    , 0.71875   , 0.70833333,\n",
       "        0.72916667, 0.70833333, 0.70833333, 0.69791667, 0.70833333,\n",
       "        0.69791667, 0.6875    , 0.73958333, 0.70833333, 0.72916667,\n",
       "        0.65625   , 0.69791667, 0.70833333, 0.71875   , 0.72916667,\n",
       "        0.66666667, 0.69791667, 0.67708333, 0.73958333, 0.72916667,\n",
       "        0.69791667, 0.75      , 0.73958333, 0.69791667, 0.70833333,\n",
       "        0.71875   , 0.69791667, 0.70833333, 0.75      , 0.70833333,\n",
       "        0.63541667, 0.75      , 0.71875   , 0.69791667, 0.73958333,\n",
       "        0.6875    , 0.67708333, 0.70833333, 0.71875   , 0.71875   ,\n",
       "        0.76041667, 0.70833333, 0.67708333, 0.72916667, 0.71875   ,\n",
       "        0.76041667, 0.70833333, 0.78125   , 0.73958333, 0.71875   ,\n",
       "        0.69791667, 0.67708333, 0.72916667, 0.6875    , 0.70833333,\n",
       "        0.73958333, 0.65625   , 0.78125   , 0.71875   , 0.69791667,\n",
       "        0.60416667, 0.67708333, 0.71875   , 0.71875   , 0.71875   ,\n",
       "        0.73958333, 0.72916667, 0.64583333, 0.70833333, 0.70833333]),\n",
       " 'mean_test_score': array([0.66666667, 0.65833333, 0.6875    , 0.66041667, 0.69375   ,\n",
       "        0.68125   , 0.65625   , 0.67708333, 0.67916667, 0.66875   ,\n",
       "        0.67708333, 0.68958333, 0.68541667, 0.70208333, 0.69791667,\n",
       "        0.68333333, 0.69791667, 0.68958333, 0.68958333, 0.69791667,\n",
       "        0.68333333, 0.68125   , 0.67708333, 0.70833333, 0.7       ,\n",
       "        0.65208333, 0.68958333, 0.70625   , 0.69583333, 0.70833333,\n",
       "        0.69166667, 0.6625    , 0.70625   , 0.68958333, 0.69791667,\n",
       "        0.67291667, 0.69583333, 0.69583333, 0.67916667, 0.68333333,\n",
       "        0.69375   , 0.67083333, 0.7       , 0.70833333, 0.70208333,\n",
       "        0.6625    , 0.675     , 0.71875   , 0.67916667, 0.69375   ,\n",
       "        0.70833333, 0.71458333, 0.70208333, 0.68333333, 0.69583333,\n",
       "        0.69375   , 0.68541667, 0.68958333, 0.71041667, 0.70833333,\n",
       "        0.68541667, 0.70625   , 0.70416667, 0.69166667, 0.70208333,\n",
       "        0.62291667, 0.66666667, 0.67291667, 0.68541667, 0.69791667,\n",
       "        0.69583333, 0.70625   , 0.6875    , 0.675     , 0.68125   ,\n",
       "        0.61875   , 0.70208333, 0.68541667, 0.70208333, 0.67708333,\n",
       "        0.63541667, 0.675     , 0.67708333, 0.69583333, 0.66666667,\n",
       "        0.65625   , 0.68541667, 0.68333333, 0.6875    , 0.68333333,\n",
       "        0.65208333, 0.68541667, 0.68541667, 0.69375   , 0.69375   ,\n",
       "        0.65208333, 0.69583333, 0.67916667, 0.69166667, 0.68958333,\n",
       "        0.67291667, 0.67916667, 0.6875    , 0.68125   , 0.68333333,\n",
       "        0.68333333, 0.70833333, 0.69583333, 0.7       , 0.69375   ,\n",
       "        0.68333333, 0.68333333, 0.70625   , 0.71666667, 0.68333333,\n",
       "        0.68958333, 0.71041667, 0.68125   , 0.69791667, 0.7       ,\n",
       "        0.70208333, 0.7125    , 0.6875    , 0.68958333, 0.69791667,\n",
       "        0.65833333, 0.71041667, 0.68958333, 0.71458333, 0.68125   ,\n",
       "        0.68125   , 0.73333333, 0.69166667, 0.71041667, 0.68958333,\n",
       "        0.68958333, 0.68541667, 0.69583333, 0.6875    , 0.69583333,\n",
       "        0.69791667, 0.6875    , 0.69166667, 0.69583333, 0.68541667,\n",
       "        0.68958333, 0.7125    , 0.67708333, 0.67916667, 0.69791667,\n",
       "        0.66666667, 0.69791667, 0.70208333, 0.6875    , 0.69583333,\n",
       "        0.74166667, 0.70416667, 0.67083333, 0.70416667, 0.69791667,\n",
       "        0.64583333, 0.6625    , 0.67291667, 0.69375   , 0.69791667,\n",
       "        0.66875   , 0.69583333, 0.67708333, 0.70208333, 0.67708333,\n",
       "        0.68958333, 0.69166667, 0.68333333, 0.68958333, 0.69375   ,\n",
       "        0.67916667, 0.69166667, 0.69583333, 0.67291667, 0.675     ,\n",
       "        0.69166667, 0.66458333, 0.68333333, 0.7       , 0.68541667,\n",
       "        0.68958333, 0.69791667, 0.70625   , 0.69166667, 0.69583333,\n",
       "        0.6875    , 0.675     , 0.70208333, 0.69166667, 0.70625   ,\n",
       "        0.68333333, 0.69166667, 0.70208333, 0.68541667, 0.71041667,\n",
       "        0.65833333, 0.67083333, 0.6875    , 0.6875    , 0.70833333,\n",
       "        0.675     , 0.675     , 0.67916667, 0.67083333, 0.69583333,\n",
       "        0.72291667, 0.67708333, 0.69583333, 0.69791667, 0.7       ,\n",
       "        0.67708333, 0.69791667, 0.68958333, 0.68958333, 0.71875   ,\n",
       "        0.67708333, 0.72083333, 0.68541667, 0.70625   , 0.7       ,\n",
       "        0.69791667, 0.68541667, 0.7       , 0.6875    , 0.68958333,\n",
       "        0.68958333, 0.69583333, 0.71875   , 0.69375   , 0.70416667,\n",
       "        0.65416667, 0.68541667, 0.68958333, 0.68333333, 0.69791667,\n",
       "        0.6375    , 0.6625    , 0.69375   , 0.66875   , 0.67916667,\n",
       "        0.64791667, 0.69791667, 0.69791667, 0.67291667, 0.68958333,\n",
       "        0.67083333, 0.68958333, 0.70208333, 0.68541667, 0.69583333,\n",
       "        0.66041667, 0.67291667, 0.6875    , 0.70208333, 0.69791667,\n",
       "        0.7       , 0.68958333, 0.69583333, 0.70208333, 0.70416667,\n",
       "        0.69166667, 0.68125   , 0.71458333, 0.7       , 0.7125    ,\n",
       "        0.7       , 0.67083333, 0.70208333, 0.69375   , 0.67916667,\n",
       "        0.67916667, 0.69791667, 0.68958333, 0.69791667, 0.70416667,\n",
       "        0.63125   , 0.675     , 0.70833333, 0.69791667, 0.71041667,\n",
       "        0.68541667, 0.7       , 0.69166667, 0.70416667, 0.69375   ,\n",
       "        0.69583333, 0.72916667, 0.69375   , 0.70625   , 0.675     ,\n",
       "        0.67916667, 0.69166667, 0.675     , 0.7       , 0.71041667,\n",
       "        0.6875    , 0.67708333, 0.6875    , 0.70208333, 0.68333333,\n",
       "        0.67291667, 0.6875    , 0.68541667, 0.70208333, 0.66875   ,\n",
       "        0.68125   , 0.68541667, 0.68125   , 0.68333333, 0.68333333,\n",
       "        0.72291667, 0.7       , 0.7125    , 0.71458333, 0.69166667,\n",
       "        0.62083333, 0.65208333, 0.68125   , 0.68333333, 0.67708333,\n",
       "        0.67291667, 0.675     , 0.67916667, 0.69375   , 0.67291667,\n",
       "        0.67916667, 0.67291667, 0.69166667, 0.68125   , 0.69375   ,\n",
       "        0.65      , 0.70208333, 0.68333333, 0.70416667, 0.68125   ,\n",
       "        0.67291667, 0.6875    , 0.68541667, 0.69375   , 0.69375   ,\n",
       "        0.675     , 0.71458333, 0.70208333, 0.69791667, 0.69583333,\n",
       "        0.67291667, 0.675     , 0.70416667, 0.70416667, 0.69166667,\n",
       "        0.65416667, 0.68333333, 0.68125   , 0.6875    , 0.6875    ,\n",
       "        0.67291667, 0.71458333, 0.69166667, 0.7       , 0.69166667,\n",
       "        0.66666667, 0.70208333, 0.70833333, 0.68333333, 0.69375   ,\n",
       "        0.69791667, 0.67916667, 0.68333333, 0.69375   , 0.67708333,\n",
       "        0.69791667, 0.73541667, 0.70416667, 0.69375   , 0.68958333,\n",
       "        0.66458333, 0.64583333, 0.69166667, 0.68958333, 0.7       ,\n",
       "        0.68333333, 0.67291667, 0.6875    , 0.69375   , 0.69583333,\n",
       "        0.67291667, 0.67291667, 0.68541667, 0.69791667, 0.69375   ,\n",
       "        0.64791667, 0.65833333, 0.70208333, 0.68333333, 0.675     ,\n",
       "        0.64375   , 0.67083333, 0.64583333, 0.67708333, 0.69583333,\n",
       "        0.675     , 0.66666667, 0.66666667, 0.67708333, 0.68541667,\n",
       "        0.65833333, 0.66041667, 0.7       , 0.68541667, 0.70208333,\n",
       "        0.7       , 0.70625   , 0.67708333, 0.7       , 0.69583333,\n",
       "        0.66666667, 0.68333333, 0.6875    , 0.69375   , 0.69791667,\n",
       "        0.69583333, 0.69791667, 0.68958333, 0.69166667, 0.70208333,\n",
       "        0.65833333, 0.675     , 0.69583333, 0.6875    , 0.68125   ,\n",
       "        0.67916667, 0.69791667, 0.69375   , 0.70208333, 0.7       ,\n",
       "        0.68958333, 0.68125   , 0.68541667, 0.69791667, 0.69375   ,\n",
       "        0.70208333, 0.70208333, 0.6875    , 0.68541667, 0.68333333,\n",
       "        0.65208333, 0.68541667, 0.70416667, 0.68541667, 0.68541667,\n",
       "        0.675     , 0.68541667, 0.68958333, 0.69583333, 0.67916667,\n",
       "        0.66041667, 0.67083333, 0.69791667, 0.69166667, 0.68958333,\n",
       "        0.67083333, 0.69375   , 0.67083333, 0.68333333, 0.69375   ,\n",
       "        0.70208333, 0.70208333, 0.68958333, 0.66041667, 0.69583333,\n",
       "        0.67291667, 0.69791667, 0.69791667, 0.7       , 0.69583333,\n",
       "        0.67083333, 0.65416667, 0.68333333, 0.67291667, 0.67083333,\n",
       "        0.68333333, 0.6875    , 0.68541667, 0.70416667, 0.69166667,\n",
       "        0.66875   , 0.65      , 0.69583333, 0.69791667, 0.6875    ,\n",
       "        0.69375   , 0.69166667, 0.67916667, 0.68541667, 0.6875    ,\n",
       "        0.67291667, 0.67083333, 0.6875    , 0.69583333, 0.68958333,\n",
       "        0.68541667, 0.67708333, 0.68125   , 0.70625   , 0.68541667,\n",
       "        0.67083333, 0.70833333, 0.69791667, 0.6875    , 0.70833333,\n",
       "        0.67291667, 0.7       , 0.70833333, 0.68958333, 0.69583333,\n",
       "        0.6875    , 0.6875    , 0.69375   , 0.69791667, 0.70625   ,\n",
       "        0.67083333, 0.71041667, 0.69791667, 0.6875    , 0.68958333,\n",
       "        0.66041667, 0.68333333, 0.68333333, 0.67291667, 0.70416667,\n",
       "        0.67916667, 0.7       , 0.6875    , 0.68958333, 0.68333333,\n",
       "        0.67708333, 0.6875    , 0.69375   , 0.70833333, 0.67916667,\n",
       "        0.6625    , 0.66875   , 0.69583333, 0.68541667, 0.70416667,\n",
       "        0.71458333, 0.69166667, 0.67083333, 0.6875    , 0.69375   ,\n",
       "        0.67083333, 0.66458333, 0.68958333, 0.68958333, 0.68333333,\n",
       "        0.65625   , 0.65      , 0.67916667, 0.66666667, 0.67916667,\n",
       "        0.67291667, 0.67916667, 0.69583333, 0.6875    , 0.68541667,\n",
       "        0.67916667, 0.71041667, 0.68541667, 0.6875    , 0.68125   ,\n",
       "        0.66458333, 0.68958333, 0.70208333, 0.69166667, 0.6875    ,\n",
       "        0.67916667, 0.68333333, 0.69166667, 0.70208333, 0.69791667,\n",
       "        0.66041667, 0.70625   , 0.68333333, 0.7125    , 0.70625   ,\n",
       "        0.66458333, 0.68541667, 0.67083333, 0.68958333, 0.68958333,\n",
       "        0.68541667, 0.70208333, 0.68541667, 0.71041667, 0.7       ,\n",
       "        0.67708333, 0.69583333, 0.70416667, 0.68958333, 0.69583333,\n",
       "        0.7       , 0.69583333, 0.69375   , 0.69166667, 0.68125   ,\n",
       "        0.67083333, 0.69375   , 0.7       , 0.69583333, 0.71458333,\n",
       "        0.69583333, 0.69166667, 0.7       , 0.72708333, 0.70416667,\n",
       "        0.71041667, 0.7       , 0.70208333, 0.69791667, 0.68125   ,\n",
       "        0.69583333, 0.69166667, 0.70625   , 0.68958333, 0.68333333,\n",
       "        0.69166667, 0.67708333, 0.7       , 0.70625   , 0.68958333,\n",
       "        0.69375   , 0.69583333, 0.68333333, 0.68541667, 0.69375   ]),\n",
       " 'std_test_score': array([0.03423266, 0.05644257, 0.04468252, 0.03461093, 0.06574889,\n",
       "        0.02041241, 0.03423266, 0.03486083, 0.05120086, 0.0463044 ,\n",
       "        0.05311479, 0.06123724, 0.04340139, 0.05      , 0.06002025,\n",
       "        0.03875224, 0.04114254, 0.05527708, 0.04903584, 0.0497389 ,\n",
       "        0.02990146, 0.0602368 , 0.03841477, 0.06555055, 0.03691676,\n",
       "        0.02243819, 0.03572173, 0.04289846, 0.04135299, 0.04370037,\n",
       "        0.04497299, 0.05651942, 0.05527708, 0.02585349, 0.04269563,\n",
       "        0.04249183, 0.02224391, 0.04903584, 0.0344853 , 0.03985651,\n",
       "        0.03131937, 0.04497299, 0.01214782, 0.03294039, 0.04399732,\n",
       "        0.03761556, 0.02748105, 0.02795085, 0.03807431, 0.04639804,\n",
       "        0.01743042, 0.03875224, 0.06541799, 0.041978  , 0.04289846,\n",
       "        0.03131937, 0.03919768, 0.03919768, 0.03047654, 0.04419417,\n",
       "        0.04439016, 0.02411633, 0.06607813, 0.04039733, 0.05128556,\n",
       "        0.04187448, 0.06686169, 0.01932004, 0.04723243, 0.06319063,\n",
       "        0.06298424, 0.0463044 , 0.04218428, 0.03632416, 0.02916667,\n",
       "        0.03267581, 0.04093101, 0.05408648, 0.03644345, 0.04061164,\n",
       "        0.03952847, 0.02019867, 0.04007372, 0.05644257, 0.04468252,\n",
       "        0.04007372, 0.04768968, 0.0477806 , 0.04658475, 0.04545297,\n",
       "        0.03461093, 0.03385016, 0.04340139, 0.05803495, 0.04592793,\n",
       "        0.08902442, 0.05245699, 0.04991312, 0.03397814, 0.05034602,\n",
       "        0.05      , 0.0344853 , 0.04419417, 0.0576598 , 0.05212498,\n",
       "        0.04299952, 0.04419417, 0.04535738, 0.04814258, 0.03761556,\n",
       "        0.04497299, 0.03875224, 0.05120086, 0.06159061, 0.04497299,\n",
       "        0.06501869, 0.03572173, 0.02602082, 0.04564355, 0.04028975,\n",
       "        0.02338536, 0.0477806 , 0.05017331, 0.05833333, 0.0389756 ,\n",
       "        0.06332785, 0.04028975, 0.03919768, 0.0557462 , 0.03200477,\n",
       "        0.06095308, 0.05335937, 0.05      , 0.04439016, 0.05120086,\n",
       "        0.05448624, 0.03254271, 0.04389856, 0.04704829, 0.04187448,\n",
       "        0.03784563, 0.05392575, 0.06270799, 0.04859127, 0.04028975,\n",
       "        0.05368374, 0.04299952, 0.05060399, 0.04947643, 0.05781015,\n",
       "        0.05667279, 0.04061164, 0.02684187, 0.04370037, 0.02748105,\n",
       "        0.04439016, 0.04448783, 0.06270799, 0.03761556, 0.04007372,\n",
       "        0.05145454, 0.05535554, 0.04093101, 0.041978  , 0.04516559,\n",
       "        0.03186887, 0.04768968, 0.02716334, 0.03584302, 0.04704829,\n",
       "        0.05758448, 0.02763854, 0.04639804, 0.04389856, 0.02990146,\n",
       "        0.0344853 , 0.05086065, 0.03974747, 0.05613414, 0.04389856,\n",
       "        0.03061862, 0.03919768, 0.03267581, 0.05796012, 0.03974747,\n",
       "        0.06263873, 0.0372678 , 0.02319902, 0.03523236, 0.02825971,\n",
       "        0.0497389 , 0.04535738, 0.04039733, 0.04956407, 0.04768968,\n",
       "        0.0477806 , 0.01412985, 0.05043216, 0.05368374, 0.03572173,\n",
       "        0.05796012, 0.04249183, 0.04269563, 0.02871677, 0.02795085,\n",
       "        0.05327797, 0.0463044 , 0.03118048, 0.03644345, 0.02748105,\n",
       "        0.03267581, 0.03841477, 0.03320287, 0.04419417, 0.04768968,\n",
       "        0.02871677, 0.04468252, 0.04028975, 0.04535738, 0.03486083,\n",
       "        0.05551214, 0.02667968, 0.03118048, 0.04439016, 0.04903584,\n",
       "        0.06940971, 0.05245699, 0.05720638, 0.04564355, 0.04991312,\n",
       "        0.0463044 , 0.0375    , 0.03547789, 0.02684187, 0.02144923,\n",
       "        0.04028975, 0.0375    , 0.05870418, 0.05043216, 0.0389756 ,\n",
       "        0.03254271, 0.041978  , 0.04592793, 0.05162297, 0.05162297,\n",
       "        0.05870418, 0.03294039, 0.05628857, 0.0576598 , 0.01666667,\n",
       "        0.03875224, 0.05644257, 0.03267581, 0.03186887, 0.04814258,\n",
       "        0.04497299, 0.01692508, 0.0497389 , 0.04399732, 0.05060399,\n",
       "        0.04439016, 0.05566829, 0.05833333, 0.04299952, 0.04912428,\n",
       "        0.04497299, 0.02684187, 0.04249183, 0.02975595, 0.04249183,\n",
       "        0.04903584, 0.04545297, 0.04145781, 0.03584302, 0.02825971,\n",
       "        0.025     , 0.03159531, 0.04859127, 0.05743354, 0.03761556,\n",
       "        0.02602082, 0.05682576, 0.03547789, 0.04930066, 0.03047654,\n",
       "        0.03864008, 0.02825971, 0.02990146, 0.04956407, 0.04399732,\n",
       "        0.03254271, 0.04061164, 0.05212498, 0.04723243, 0.03919768,\n",
       "        0.03320287, 0.04823265, 0.04768968, 0.04487637, 0.0463044 ,\n",
       "        0.03019037, 0.08149003, 0.03423266, 0.04399732, 0.03703414,\n",
       "        0.03584302, 0.01141089, 0.04991312, 0.01932004, 0.03385016,\n",
       "        0.05535554, 0.06263873, 0.03875224, 0.02041241, 0.0477806 ,\n",
       "        0.03584302, 0.05077524, 0.03397814, 0.05      , 0.05840769,\n",
       "        0.01559024, 0.05      , 0.0752888 , 0.04912428, 0.05705443,\n",
       "        0.06407732, 0.0375    , 0.05120086, 0.04399732, 0.04093101,\n",
       "        0.03320287, 0.04448783, 0.02144923, 0.03761556, 0.03875224,\n",
       "        0.06407732, 0.04093101, 0.041978  , 0.03333333, 0.04639804,\n",
       "        0.0477806 , 0.04516559, 0.04991312, 0.04399732, 0.04350128,\n",
       "        0.0601647 , 0.04249183, 0.04448783, 0.06972167, 0.03864008,\n",
       "        0.04497299, 0.0344853 , 0.02429563, 0.04497299, 0.04686342,\n",
       "        0.04723243, 0.03703414, 0.04249183, 0.04419417, 0.04320092,\n",
       "        0.05496211, 0.041978  , 0.05535554, 0.04903584, 0.041978  ,\n",
       "        0.02551552, 0.0477806 , 0.04320092, 0.05212498, 0.04545297,\n",
       "        0.03159531, 0.06366961, 0.04299952, 0.04497299, 0.0488585 ,\n",
       "        0.04516559, 0.02841288, 0.02990146, 0.03267581, 0.03320287,\n",
       "        0.04187448, 0.05855612, 0.03523236, 0.05870418, 0.02901748,\n",
       "        0.04686342, 0.05212498, 0.02282177, 0.05086065, 0.05245699,\n",
       "        0.06928454, 0.04868051, 0.04289846, 0.04114254, 0.0477806 ,\n",
       "        0.04723243, 0.0669914 , 0.03584302, 0.03267581, 0.03919768,\n",
       "        0.03186887, 0.02990146, 0.04114254, 0.04370037, 0.03320287,\n",
       "        0.04238956, 0.05855612, 0.04750731, 0.04516559, 0.05368374,\n",
       "        0.03186887, 0.02144923, 0.03864008, 0.04389856, 0.05212498,\n",
       "        0.0463044 , 0.02825971, 0.06215181, 0.05162297, 0.04535738,\n",
       "        0.04796194, 0.04093101, 0.04370037, 0.05086065, 0.05017331,\n",
       "        0.04135299, 0.05145454, 0.05077524, 0.05613414, 0.04639804,\n",
       "        0.03919768, 0.0344853 , 0.06088183, 0.0488585 , 0.03267581,\n",
       "        0.02411633, 0.03294039, 0.03818813, 0.05690208, 0.05644257,\n",
       "        0.06763618, 0.04350128, 0.04487637, 0.03423266, 0.03584302,\n",
       "        0.04956407, 0.03761556, 0.02465033, 0.04238956, 0.03644345,\n",
       "        0.04912428, 0.01792151, 0.03875224, 0.05527708, 0.05833333,\n",
       "        0.04991312, 0.05796012, 0.04028975, 0.02667968, 0.02825971,\n",
       "        0.08191501, 0.03397814, 0.01743042, 0.03267581, 0.04535738,\n",
       "        0.05043216, 0.02144923, 0.04686342, 0.05690208, 0.04039733,\n",
       "        0.08244316, 0.04956407, 0.0375    , 0.04145781, 0.03320287,\n",
       "        0.0529511 , 0.0497389 , 0.04166667, 0.04135299, 0.03974747,\n",
       "        0.05376453, 0.05758448, 0.03333333, 0.02684187, 0.05128556,\n",
       "        0.04497299, 0.0389756 , 0.06501869, 0.04093101, 0.05043216,\n",
       "        0.02901748, 0.05496211, 0.04723243, 0.04218428, 0.03668087,\n",
       "        0.02990146, 0.01412985, 0.03632416, 0.04583333, 0.03668087,\n",
       "        0.03461093, 0.05914612, 0.05392575, 0.04439016, 0.05833333,\n",
       "        0.03320287, 0.01743042, 0.04912428, 0.05034602, 0.03047654,\n",
       "        0.04686342, 0.03159531, 0.05229125, 0.05017331, 0.03159531,\n",
       "        0.03523236, 0.02319902, 0.06488505, 0.04903584, 0.04238956,\n",
       "        0.04658475, 0.04218428, 0.03644345, 0.02871677, 0.03919768,\n",
       "        0.04639804, 0.02748105, 0.03486083, 0.05472469, 0.03254271,\n",
       "        0.02338536, 0.05914612, 0.04592793, 0.04093101, 0.02916667,\n",
       "        0.03510896, 0.02667968, 0.03668087, 0.04439016, 0.02841288,\n",
       "        0.05145454, 0.06620937, 0.06305311, 0.04166667, 0.04439016,\n",
       "        0.05613414, 0.02825971, 0.04439016, 0.04859127, 0.03644345,\n",
       "        0.05      , 0.04145781, 0.04686342, 0.03608439, 0.02841288,\n",
       "        0.04448783, 0.04947643, 0.04677072, 0.05566829, 0.04399732,\n",
       "        0.06488505, 0.03761556, 0.05162297, 0.04419417, 0.05327797,\n",
       "        0.00833333, 0.04082483, 0.05162297, 0.06073908, 0.03974747,\n",
       "        0.05720638, 0.01020621, 0.02411633, 0.03784563, 0.05128556,\n",
       "        0.05327797, 0.05327797, 0.04093101, 0.04399732, 0.05432669,\n",
       "        0.04135299, 0.02990146, 0.04093101, 0.03584302, 0.04166667,\n",
       "        0.03761556, 0.06159061, 0.03397814, 0.03930825, 0.05034602,\n",
       "        0.03047654, 0.05870418, 0.04912428, 0.03691676, 0.04238956,\n",
       "        0.05162297, 0.0477806 , 0.04903584, 0.04814258, 0.04289846,\n",
       "        0.04750731, 0.05644257, 0.03461093, 0.0344853 , 0.0344853 ,\n",
       "        0.03572173, 0.04082483, 0.04686342, 0.05086065, 0.04399732,\n",
       "        0.05416667, 0.05651942, 0.0344853 , 0.05034602, 0.03644345,\n",
       "        0.05566829, 0.05128556, 0.05120086, 0.02825971, 0.04497299,\n",
       "        0.04859127, 0.03510896, 0.04592793, 0.03294039, 0.04350128,\n",
       "        0.04289846, 0.02041241, 0.04723243, 0.05034602, 0.04956407,\n",
       "        0.04823265, 0.02185018, 0.03254271, 0.02124591, 0.0344853 ,\n",
       "        0.04039733, 0.02411633, 0.02841288, 0.04289846, 0.03875224]),\n",
       " 'rank_test_score': array([587, 610, 365, 602, 259, 452, 615, 505, 483, 578, 505, 293, 375,\n",
       "         93, 144, 450, 168, 307, 307, 168, 414, 456, 497,  37, 118, 621,\n",
       "        293,  50, 197,  40, 262, 598,  50, 307, 144, 535, 197, 197, 483,\n",
       "        414, 230, 563, 118,  40,  93, 598, 518,   9, 483, 230,  40,  13,\n",
       "         93, 414, 223, 230, 399, 307,  30,  37, 374,  50,  77, 262,  93,\n",
       "        638, 587, 535, 399, 144, 197,  50, 340, 518, 456, 640,  93, 375,\n",
       "         93, 505, 636, 518, 497, 197, 583, 615, 375, 414, 340, 414, 621,\n",
       "        375, 375, 230, 230, 621, 197, 483, 262, 307, 548, 472, 365, 456,\n",
       "        414, 414,  40, 184, 115, 230, 414, 414,  50,  12, 450, 307,  30,\n",
       "        452, 144, 118,  83,  22, 340, 293, 144, 610,  26, 293,  13, 456,\n",
       "        456,   3, 262,  30, 307, 307, 399, 197, 365, 197, 144, 337, 262,\n",
       "        184, 375, 307,  21, 505, 472, 144, 583, 144,  83, 340, 184,   1,\n",
       "         66, 558,  66, 144, 631, 601, 535, 230, 144, 578, 197, 505,  93,\n",
       "        497, 307, 262, 414, 293, 230, 483, 262, 197, 548, 518, 262, 592,\n",
       "        414, 118, 399, 293, 144,  50, 262, 184, 365, 530,  83, 262,  50,\n",
       "        414, 262,  83, 399,  26, 610, 563, 365, 340,  40, 530, 518, 472,\n",
       "        563, 197,   6, 505, 197, 168, 118, 497, 168, 307, 307,   9, 505,\n",
       "          8, 375,  50, 118, 168, 399, 118, 340, 293, 307, 184,   9, 230,\n",
       "         77, 618, 399, 307, 414, 144, 635, 598, 226, 578, 472, 629, 144,\n",
       "        168, 548, 293, 563, 307,  83, 375, 184, 602, 535, 340,  93, 144,\n",
       "        118, 307, 184,  83,  77, 262, 456,  13, 115,  22, 118, 563,  83,\n",
       "        230, 483, 483, 144, 307, 144,  66, 637, 518,  40, 144,  30, 375,\n",
       "        118, 262,  66, 230, 184,   4, 230,  50, 530, 472, 262, 518, 118,\n",
       "         26, 337, 497, 365,  93, 414, 535, 337, 399,  93, 577, 456, 375,\n",
       "        456, 414, 414,   6, 118,  22,  13, 262, 639, 621, 456, 414, 497,\n",
       "        535, 518, 483, 230, 535, 472, 548, 262, 456, 230, 626,  93, 414,\n",
       "         66, 471, 548, 340, 399, 230, 226, 518,  13,  93, 168, 197, 535,\n",
       "        518,  66,  77, 262, 620, 414, 456, 365, 340, 535,  13, 262, 118,\n",
       "        262, 587,  83,  37, 414, 230, 144, 472, 414, 230, 505, 144,   2,\n",
       "         66, 259, 307, 593, 631, 262, 307, 118, 414, 535, 340, 230, 197,\n",
       "        535, 535, 375, 168, 230, 630, 610,  93, 414, 518, 634, 563, 631,\n",
       "        505, 197, 530, 583, 587, 505, 375, 609, 602, 118, 375,  93, 118,\n",
       "         50, 505, 118, 184, 583, 414, 340, 230, 168, 223, 168, 293, 262,\n",
       "         93, 610, 530, 197, 340, 452, 472, 144, 226,  93, 118, 293, 456,\n",
       "        375, 144, 230,  93,  93, 340, 399, 414, 621, 375,  66, 375, 399,\n",
       "        518, 399, 307, 197, 472, 602, 563, 144, 262, 307, 558, 259, 563,\n",
       "        414, 230,  83,  93, 307, 602, 197, 548, 168, 168, 118, 223, 563,\n",
       "        618, 414, 548, 558, 414, 340, 375,  66, 262, 578, 628, 184, 144,\n",
       "        340, 230, 262, 483, 399, 340, 548, 563, 340, 184, 293, 375, 497,\n",
       "        456,  50, 399, 563,  40, 144, 340,  40, 548, 118,  40, 307, 197,\n",
       "        340, 340, 230, 168,  65, 558,  30, 168, 365, 293, 602, 414, 414,\n",
       "        535,  77, 472, 118, 340, 307, 414, 497, 340, 230,  40, 483, 597,\n",
       "        578, 197, 399,  66,  13, 262, 563, 340, 226, 563, 593, 293, 307,\n",
       "        414, 617, 626, 472, 587, 483, 548, 483, 197, 340, 375, 483,  26,\n",
       "        375, 365, 452, 593, 293,  93, 262, 340, 483, 414, 262,  93, 168,\n",
       "        602,  50, 414,  22,  50, 593, 375, 558, 307, 307, 375,  83, 375,\n",
       "         30, 115, 505, 197,  77, 307, 184, 118, 197, 230, 262, 456, 563,\n",
       "        230, 118, 197,  13, 197, 262, 118,   5,  66,  30, 118,  93, 168,\n",
       "        456, 184, 262,  50, 307, 414, 262, 505, 118,  50, 307, 230, 197,\n",
       "        414, 375, 230])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando os melhores parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 20,\n",
       " 'min_samples_leaf': 15,\n",
       " 'min_samples_split': 15,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando o melhor score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7416666666666666"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
