{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline é um modulo da biblioteca scikit-learn que permite agrupar transformadores e preditores.\n",
    "\n",
    "Vantagens de utilizar pipelines:\n",
    "\n",
    "Melhora a produtividade.\n",
    "\n",
    "Facilita o uso de técnicas de validação e seleção de modelos.\n",
    "\n",
    "Evita erros de manipulação de conjuntos de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Andre\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-learn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    joblib-0.14.1              |             py_0         202 KB\n",
      "    scikit-learn-0.22.1        |   py37h6288b17_0         6.3 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         6.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  joblib             pkgs/main/noarch::joblib-0.14.1-py_0\n",
      "  scikit-learn       pkgs/main/win-64::scikit-learn-0.22.1-py37h6288b17_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "scikit-learn-0.22.1  | 6.3 MB    |            |   0% \n",
      "scikit-learn-0.22.1  | 6.3 MB    |            |   0% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | 1          |   2% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | 3          |   3% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | 3          |   4% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | 5          |   5% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | 6          |   7% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | 8          |   9% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #          |  10% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #2         |  12% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #4         |  14% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #6         |  16% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #8         |  18% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ##         |  20% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ##2        |  22% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ##4        |  24% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ##6        |  26% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ##8        |  29% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ###        |  31% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ###2       |  33% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ###5       |  35% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ###7       |  37% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ###9       |  39% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ####1      |  42% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ####3      |  44% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ####5      |  46% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ####8      |  48% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #####      |  50% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #####2     |  52% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #####4     |  54% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #####6     |  57% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #####8     |  59% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ######     |  61% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ######2    |  63% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ######4    |  65% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ######7    |  67% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ######9    |  69% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #######    |  71% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #######2   |  73% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #######4   |  74% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #######6   |  76% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #######8   |  78% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #######9   |  80% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ########1  |  82% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ########3  |  84% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ########5  |  86% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ########7  |  88% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ########9  |  90% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #########1 |  92% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #########3 |  94% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #########5 |  96% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | #########8 |  98% \n",
      "scikit-learn-0.22.1  | 6.3 MB    | ########## | 100% \n",
      "\n",
      "joblib-0.14.1        | 202 KB    |            |   0% \n",
      "joblib-0.14.1        | 202 KB    | ##3        |  24% \n",
      "joblib-0.14.1        | 202 KB    | ########7  |  87% \n",
      "joblib-0.14.1        | 202 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\andre\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.17.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1319 sha256=c4996b1bb8ebd5c37fa5c41eabe4b7222c143d22869351d532c37cd7f341f251\n",
      "  Stored in directory: c:\\users\\andre\\appdata\\local\\pip\\cache\\wheels\\46\\ef\\c3\\157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importanto o módulo.\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar o pipeline para criar um objeto que encapsula a tarefa de pré-processamento e classificação (usando um algoritmo de Machine Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o módulo de pré-processamento:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Em seguida importanto o módulo do nosso classificador (regressão logística, neste caso)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset\n",
    "\n",
    "from sklearn import datasets\n",
    "dataset = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O próximo passo é separar as classes dos dados de treino.\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vou utilizar o método train_test_split para separar os dados de treino e teste\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a pipeline após a separação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No código abaixo, foi criado um objeto chamado “pip_1” que será o pipeline que encapsula \n",
    "# um método de pré-processamento (StandardScaler) e um classificador (LogisticRegressĩon)\n",
    "\n",
    "pip_1 = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Com o objeto criado, vamos usar o pipeline para aplicar o pré-processamento no dado e treinar o algoritmo.\n",
    "\n",
    "pip_1.fit(X_treino,y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9371541501976285"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculando a acurácia desse modelo, fazendo uma validação cruzada.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.mean(cross_val_score(pip_1, X_treino, y_treino, cv=5)) # O parâmetro cv significa uma validação cruzada de 5 folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando pipelines\n",
    "\n",
    "Criando um outro pipeline que usará outra técnica de pré-processamento nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Com o comando acima, importamos um outro pré-processador para aplicar nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o novo pipeline.\n",
    "\n",
    "pip_2 = Pipeline([\n",
    "    ('min_max_scaler', MinMaxScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('min_max_scaler',\n",
       "                 MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar a técnica no novo pré-processador e treinar o algoritmo.\n",
    "\n",
    "pip_2.fit(X_treino,y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9019762845849802"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.mean(cross_val_score(pip_2, X_treino, y_treino, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O resultado foi diferente, isso mostra que o segundo tipo de pré-processamento ficou pior que o primeiro."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
